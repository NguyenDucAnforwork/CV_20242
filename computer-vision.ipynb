{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c1fb6a",
   "metadata": {
    "papermill": {
     "duration": 0.008075,
     "end_time": "2025-05-20T17:54:39.824505",
     "exception": false,
     "start_time": "2025-05-20T17:54:39.816430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://www.kaggle.com/code/ndannnop/computer-vision?scriptVersionId=240710736\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e265b47",
   "metadata": {
    "papermill": {
     "duration": 0.007786,
     "end_time": "2025-05-20T17:54:39.839124",
     "exception": false,
     "start_time": "2025-05-20T17:54:39.831338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f5481f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:39.853877Z",
     "iopub.status.busy": "2025-05-20T17:54:39.853625Z",
     "iopub.status.idle": "2025-05-20T17:54:51.056472Z",
     "shell.execute_reply": "2025-05-20T17:54:51.055643Z"
    },
    "papermill": {
     "duration": 11.21235,
     "end_time": "2025-05-20T17:54:51.057955",
     "exception": false,
     "start_time": "2025-05-20T17:54:39.845605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import random\n",
    "import math # Needed for ceiling division\n",
    "\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "\n",
    "# Global OCR reader for efficiency\n",
    "_ocr_reader = None\n",
    "\n",
    "def get_ocr_reader(languages=[\"en\"]):\n",
    "    global _ocr_reader\n",
    "    if _ocr_reader is None:\n",
    "        _ocr_reader = easyocr.Reader(languages)\n",
    "    return _ocr_reader\n",
    "\n",
    "def extract_patches(image_array, num_patch=3, patch_size=(105, 105), \n",
    "                    extract_text=True, min_text_coverage=0.3, max_attempts=20):\n",
    "    patch_h, patch_w = patch_size\n",
    "\n",
    "    # Determine if grayscale or color\n",
    "    if image_array.ndim == 2:\n",
    "        h, w = image_array.shape\n",
    "        is_grayscale = True\n",
    "    elif image_array.ndim == 3:\n",
    "        h, w, _ = image_array.shape\n",
    "        is_grayscale = False\n",
    "    else:\n",
    "        print(f\"Unexpected image shape: {image_array.shape}\")\n",
    "        return []\n",
    "\n",
    "    # === Step 1: Resize image to height = 105, maintain aspect ratio ===\n",
    "    scale_factor = patch_h / h\n",
    "    new_w = int(w * scale_factor)\n",
    "    if is_grayscale:\n",
    "        resized = cv2.resize(image_array, (new_w, patch_h), interpolation=cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        resized = cv2.resize(image_array, (new_w, patch_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # === Step 2: Check if width is enough for patch ===\n",
    "    if new_w < patch_w:\n",
    "        return []\n",
    "\n",
    "    # === Step 3: If not extracting text, return random crops ===\n",
    "    if not extract_text:\n",
    "        patches = []\n",
    "        for _ in range(num_patch):\n",
    "            x = np.random.randint(0, new_w - patch_w + 1)\n",
    "            if is_grayscale:\n",
    "                patch = resized[:, x:x + patch_w]\n",
    "            else:\n",
    "                patch = resized[:, x:x + patch_w, :]\n",
    "            patches.append(patch)\n",
    "        return patches\n",
    "\n",
    "    # === Step 4: Try to find text patches using OCR ===\n",
    "    reader = get_ocr_reader()\n",
    "    text_patches = []\n",
    "    attempts = 0\n",
    "\n",
    "    while len(text_patches) < num_patch and attempts < max_attempts:\n",
    "        x = np.random.randint(0, new_w - patch_w + 1)\n",
    "        if is_grayscale:\n",
    "            patch = resized[:, x:x + patch_w]\n",
    "        else:\n",
    "            patch = resized[:, x:x + patch_w, :]\n",
    "\n",
    "        # Save patch to temporary file for OCR\n",
    "        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:\n",
    "            tmp_path = tmp.name\n",
    "            patch_img = Image.fromarray(patch)\n",
    "            patch_img.save(tmp_path)\n",
    "\n",
    "        try:\n",
    "            ocr_results = reader.readtext(tmp_path)\n",
    "            os.unlink(tmp_path)\n",
    "\n",
    "            patch_area = patch_h * patch_w\n",
    "            text_area = 0\n",
    "            for bbox, text, conf in ocr_results:\n",
    "                if conf < 0.5:\n",
    "                    continue\n",
    "                bbox = [[int(p[0]), int(p[1])] for p in bbox]\n",
    "                min_x = max(0, min(p[0] for p in bbox))\n",
    "                max_x = min(patch_w, max(p[0] for p in bbox))\n",
    "                min_y = max(0, min(p[1] for p in bbox))\n",
    "                max_y = min(patch_h, max(p[1] for p in bbox))\n",
    "                if max_x > min_x and max_y > min_y:\n",
    "                    text_area += (max_x - min_x) * (max_y - min_y)\n",
    "\n",
    "            if text_area / patch_area >= min_text_coverage:\n",
    "                text_patches.append(patch)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"OCR error: {e}\")\n",
    "            try:\n",
    "                os.unlink(tmp_path)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "    return text_patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbb30c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.072959Z",
     "iopub.status.busy": "2025-05-20T17:54:51.072588Z",
     "iopub.status.idle": "2025-05-20T17:54:51.087430Z",
     "shell.execute_reply": "2025-05-20T17:54:51.086823Z"
    },
    "papermill": {
     "duration": 0.023455,
     "end_time": "2025-05-20T17:54:51.088537",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.065082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmentation functions\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "TARGET_SIZE = (105, 105)\n",
    "\n",
    "def to_uint8(img: np.ndarray) -> np.ndarray:\n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "def noise_image(img: np.ndarray, mean=0.0, std=3.0) -> np.ndarray:\n",
    "    \"\"\"Add Gaussian noise.\"\"\"\n",
    "    f = img.astype(np.float32)\n",
    "    n = np.random.normal(mean, std, f.shape).astype(np.float32)\n",
    "    return to_uint8(f + n)\n",
    "\n",
    "def blur_image(img: np.ndarray, sigma_range=(0.5, 1.5)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply a mild, randomly‐parameterized Gaussian blur.\n",
    "    \n",
    "    Args:\n",
    "        img (np.ndarray): Input image, either H×W or H×W×C, dtype uint8.\n",
    "        sigma_range (tuple): Min/max sigma for the blur kernel.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Blurred image, same shape and dtype uint8.\n",
    "    \"\"\"\n",
    "    # Ensure float for convolution\n",
    "    f = img.astype(np.float32)\n",
    "    # Randomize sigma in the given range\n",
    "    sigma = random.uniform(*sigma_range)\n",
    "    # OpenCV: kernel size (0,0) triggers automatic size based on sigma\n",
    "    if f.ndim == 2:\n",
    "        blurred = cv2.GaussianBlur(f, ksize=(0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "    else:\n",
    "        # Split channels and blur each independently\n",
    "        channels = cv2.split(f)\n",
    "        channels = [cv2.GaussianBlur(ch, ksize=(0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "                    for ch in channels]\n",
    "        blurred = cv2.merge(channels)\n",
    "    # Restore uint8\n",
    "    return np.clip(blurred, 0, 255).astype(np.uint8)\n",
    "\n",
    "def affine_rotation(img: np.ndarray, max_deg=10) -> np.ndarray:\n",
    "    \"\"\"Small random affine warp.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    # random shift on three points\n",
    "    src = np.float32([[0,0],[w-1,0],[0,h-1]])\n",
    "    dx = w * 0.05\n",
    "    dy = h * 0.05\n",
    "    dst = src + np.random.uniform([-dx, -dy], [dx, dy], src.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(src, dst)\n",
    "    warped = cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "    return warped\n",
    "\n",
    "def shading_gradient(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Multiply by a random horizontal or vertical linear illumination gradient.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    start, end = random.uniform(0.6,1.4), random.uniform(0.6,1.4)\n",
    "    if random.choice([True,False]):\n",
    "        # horizontal\n",
    "        grad = np.linspace(start, end, w, dtype=np.float32)[None,:]\n",
    "        mask = np.repeat(grad, h, axis=0)\n",
    "    else:\n",
    "        # vertical\n",
    "        grad = np.linspace(start, end, h, dtype=np.float32)[:,None]\n",
    "        mask = np.repeat(grad, w, axis=1)\n",
    "    if img.ndim==3:\n",
    "        mask = mask[:,:,None]\n",
    "    shaded = img.astype(np.float32) * mask\n",
    "    return to_uint8(shaded)\n",
    "\n",
    "def variable_aspect_ratio_preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Squeeze width by a random factor in [5/6,7/6], then pad/crop to original.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    factor = random.uniform(5/6, 7/6)\n",
    "    new_w = max(1, int(w/factor))\n",
    "    resized = cv2.resize(img, (new_w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    # pad or crop back to w x h\n",
    "    if new_w < w:\n",
    "        pad = ( (0,0), ( (w-new_w)//2, (w-new_w)-(w-new_w)//2 ) ) + ((0,0),) if img.ndim==3 else ( (0,0), ( (w-new_w)//2, (w-new_w)-(w-new_w)//2 ) )\n",
    "        resized = np.pad(resized, pad, mode='reflect')\n",
    "    else:\n",
    "        x0 = (new_w - w)//2\n",
    "        resized = resized[:, x0:x0+w]\n",
    "    return resized\n",
    "\n",
    "def final_resize(img: np.ndarray, size=TARGET_SIZE) -> np.ndarray:\n",
    "    \"\"\"Resize to target patch size.\"\"\"\n",
    "    return cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def augmentation_pipeline(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply a random subset of the six DeepFont augmentations:\n",
    "      - noise, blur, affine warp, shading, variable spacing (as AR squeeze)\n",
    "      - note: gradient_fill (Laplacian) dropped since shading covers illumination.\n",
    "    Finally, resize to TARGET_SIZE.\n",
    "    \"\"\"\n",
    "    # Ensure uint8\n",
    "    img = to_uint8(img)\n",
    "    # 1) variable aspect ratio\n",
    "    img = variable_aspect_ratio_preprocess(img)\n",
    "    # 2) choose 2–4 augmentations from the pool\n",
    "    pool = [\n",
    "        noise_image,\n",
    "        blur_image,\n",
    "        affine_rotation,\n",
    "        shading_gradient\n",
    "    ]\n",
    "    for fn in pool:\n",
    "        img = fn(img)\n",
    "    # 3) final resize\n",
    "    img = final_resize(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1debcf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.103253Z",
     "iopub.status.busy": "2025-05-20T17:54:51.103022Z",
     "iopub.status.idle": "2025-05-20T17:54:51.123867Z",
     "shell.execute_reply": "2025-05-20T17:54:51.123256Z"
    },
    "papermill": {
     "duration": 0.029853,
     "end_time": "2025-05-20T17:54:51.125028",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.095175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from io import BytesIO\n",
    "# from datasets import Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class that combines both .jpeg files and .bcf files into a single dataset.\n",
    "    This class can handle loading and patch extraction from both .jpeg and .bcf files.\n",
    "    \"\"\"\n",
    "    def __init__(self, jpeg_dir, bcf_file, label_file, testing=False, num_patch=3, patch_size=(105, 105), \n",
    "                 extract_text=False, min_text_coverage=0.3, max_attempts=20, ocr_languages=[\"en\"]):\n",
    "        \"\"\"\n",
    "        Initializes the dataset by loading both jpeg files and bcf files into one dataset.\n",
    "\n",
    "        Args:\n",
    "            jpeg_dir (str): Directory containing .jpeg files.\n",
    "            bcf_file (str): Path to the .bcf file.\n",
    "            label_file (str): Path to the label file corresponding to the .bcf file.\n",
    "            num_patch (int): Number of patches to extract per image.\n",
    "            patch_size (tuple): Tuple (height, width) for the size of the patches.\n",
    "            extract_text (bool): Whether to prioritize patches containing text\n",
    "            min_text_coverage (float): Minimum ratio of text area to patch area (0-1)\n",
    "            max_attempts (int): Maximum number of attempts to find text patches\n",
    "            ocr_languages (list): Languages for EasyOCR to detect\n",
    "        \"\"\"\n",
    "        self.jpeg_dir = jpeg_dir\n",
    "        self.bcf_file = bcf_file\n",
    "        self.label_file = label_file\n",
    "        self.testing = testing\n",
    "        self.num_patch = num_patch\n",
    "        self.patch_size = patch_size\n",
    "        self.extract_text = extract_text\n",
    "        self.min_text_coverage = min_text_coverage\n",
    "        self.max_attempts = max_attempts\n",
    "        self.ocr_languages = ocr_languages\n",
    "\n",
    "        # Initialize OCR reader if needed\n",
    "        if extract_text:\n",
    "            self.reader = get_ocr_reader(ocr_languages)\n",
    "\n",
    "        self.jpeg_data = []\n",
    "        self.bcf_data = []\n",
    "\n",
    "        # Load jpeg data\n",
    "        self._load_jpeg_data(jpeg_dir)\n",
    "\n",
    "        # Load bcf data\n",
    "        self._load_bcf_data(bcf_file, label_file)\n",
    "\n",
    "    def _extract_patches_test(self, img_array):\n",
    "        h, w = img_array.shape[:2]\n",
    "        target_h, target_w = self.patch_size\n",
    "        # 1) resize height\n",
    "        new_w = int(w * (target_h / h))\n",
    "        img = cv2.resize(img_array, (new_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
    "        patches = []\n",
    "        for _scale in range(3):\n",
    "            factor = np.random.uniform(1.5, 3.5)\n",
    "            sw = max(1, int(new_w / factor))\n",
    "            squeezed = cv2.resize(img, (sw, target_h), interpolation=cv2.INTER_LINEAR)\n",
    "            # nếu width < target_w thì pad reflect, else crop giữa\n",
    "            if sw < target_w:\n",
    "                pad = target_w - sw\n",
    "                left = pad//2; right = pad-left\n",
    "                squeezed = np.pad(squeezed,\n",
    "                                  ((0,0),(left,right)) + ((0,0),)*(img.ndim-2),\n",
    "                                  mode='reflect')\n",
    "            else:\n",
    "                x0 = (sw - target_w)//2\n",
    "                squeezed = squeezed[:, x0:x0+target_w]\n",
    "            # crop 5 patch random\n",
    "            for _ in range(5):\n",
    "                x = np.random.randint(0, target_w - target_w + 1)\n",
    "                y = np.random.randint(0,      0  + 1)  # vì height==target_h\n",
    "                patch = squeezed[y:y+target_h, x:x+target_w] if img.ndim==2 \\\n",
    "                        else squeezed[y:y+target_h, x:x+target_w, :]\n",
    "                patches.append(patch)\n",
    "        return patches\n",
    "\n",
    "    def _load_jpeg_data(self, jpeg_dir):\n",
    "        \"\"\"Loads the .jpeg files from the specified directory.\"\"\"\n",
    "        if not os.path.exists(jpeg_dir):\n",
    "            print(f\"Warning: JPEG directory {jpeg_dir} does not exist.\")\n",
    "            return\n",
    "            \n",
    "        image_filenames = [f for f in os.listdir(jpeg_dir) if f.lower().endswith(('.jpeg', '.jpg'))]\n",
    "        self.jpeg_data = [(os.path.join(jpeg_dir, f), 0) for f in image_filenames]  # Assuming label is 0 for .jpeg files\n",
    "        print(f\"Loaded {len(self.jpeg_data)} .jpeg images.\")\n",
    "\n",
    "    def _load_bcf_data(self, bcf_file, label_file):\n",
    "        \"\"\"Loads the .bcf file and the associated label file.\"\"\"\n",
    "        if not (os.path.exists(bcf_file) and os.path.exists(label_file)):\n",
    "            print(f\"Warning: BCF file {bcf_file} or label file {label_file} does not exist.\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            with open(label_file, 'rb') as f:\n",
    "                self.labels = np.frombuffer(f.read(), dtype=np.uint32)\n",
    "                print(f\"Loaded {len(self.labels)} labels from {label_file}.\")\n",
    "\n",
    "            with open(bcf_file, 'rb') as f:\n",
    "                self.num_images = np.frombuffer(f.read(8), dtype=np.int64)[0]\n",
    "                print(f\"Loaded {self.num_images} images from {bcf_file}.\")\n",
    "\n",
    "                sizes_bytes = f.read(self.num_images * 8)\n",
    "                self.image_sizes = np.frombuffer(sizes_bytes, dtype=np.int64)\n",
    "\n",
    "                self.data_start_offset = 8 + self.num_images * 8\n",
    "                self.image_offsets = np.zeros(self.num_images + 1, dtype=np.int64)\n",
    "                np.cumsum(self.image_sizes, out=self.image_offsets[1:])\n",
    "\n",
    "                for idx in range(self.num_images):\n",
    "                    self.bcf_data.append((idx, self.labels[idx]))\n",
    "                \n",
    "            print(f\"Loaded {len(self.bcf_data)} .bcf images.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading .bcf data: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of images in the combined dataset.\"\"\"\n",
    "        return len(self.jpeg_data) + len(self.bcf_data)\n",
    "\n",
    "    def _extract_patches(self, img_array):\n",
    "        \"\"\"Helper function to extract patches from an image.\"\"\"\n",
    "        return extract_patches(\n",
    "            img_array, \n",
    "            num_patch=self.num_patch, \n",
    "            patch_size=self.patch_size,\n",
    "            extract_text=self.extract_text, \n",
    "            min_text_coverage=self.min_text_coverage,\n",
    "            max_attempts=self.max_attempts\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Fetches one item with robust error handling for corrupted images.\"\"\"\n",
    "        # Handle case where idx is a list (batch loading)\n",
    "        if isinstance(idx, list):\n",
    "            # Handle batch indices properly\n",
    "            results = []\n",
    "            labels = []\n",
    "            for single_idx in idx:\n",
    "                try:\n",
    "                    patches, label = self.__getitem__(single_idx)  # Call recursively with single index\n",
    "                    if patches and label != -1:\n",
    "                        results.append(patches)\n",
    "                        labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing index {single_idx}: {e}\")\n",
    "                    # Skip this item on error\n",
    "            \n",
    "            # Return whatever valid items we were able to get\n",
    "            return results, labels\n",
    "        \n",
    "        # Original single-item loading logic\n",
    "        max_retries = 3  # Try a few times before giving up on an index\n",
    "        \n",
    "        for retry in range(max_retries):\n",
    "            try:\n",
    "                if idx < len(self.jpeg_data):\n",
    "                    # JPEG image with error handling\n",
    "                    img_path, label = self.jpeg_data[idx]\n",
    "                    try:\n",
    "                        with warnings.catch_warnings():\n",
    "                            warnings.simplefilter(\"ignore\")  # Ignore PIL warnings\n",
    "                            img = Image.open(img_path)\n",
    "                            img.verify()  # Verify image is not corrupted\n",
    "                        \n",
    "                        # Re-open since verify() closes the file\n",
    "                        img = Image.open(img_path).convert('L')\n",
    "                        img_array = np.array(img)\n",
    "                        patches = self._extract_patches(img_array)\n",
    "                        # patches = [augmentation_pipeline(patch) for patch in patches]\n",
    "                        \n",
    "                        # Clean memory\n",
    "                        del img, img_array\n",
    "                        \n",
    "                        return patches, label\n",
    "                    \n",
    "                    except (OSError, IOError, ValueError) as e:\n",
    "                        # Image is corrupted, return empty list\n",
    "                        print(f\"Warning: Corrupt image at {img_path}: {e}\")\n",
    "                        return [], -1\n",
    "                        \n",
    "                else:\n",
    "                    # BCF image with error handling\n",
    "                    bcf_idx = idx - len(self.jpeg_data)\n",
    "                    if bcf_idx >= len(self.bcf_data):\n",
    "                        return [], -1\n",
    "                        \n",
    "                    label = self.bcf_data[bcf_idx][1]\n",
    "                    offset = self.image_offsets[bcf_idx]\n",
    "                    size = self.image_sizes[bcf_idx]\n",
    "                    \n",
    "                    try:\n",
    "                        with open(self.bcf_file, 'rb') as f:\n",
    "                            f.seek(self.data_start_offset + offset)\n",
    "                            image_bytes = f.read(size)\n",
    "                        \n",
    "                        # Use BytesIO to catch corruption\n",
    "                        buffer = BytesIO(image_bytes)\n",
    "                        img = Image.open(buffer)\n",
    "                        img.verify()  # Verify it's valid\n",
    "                        \n",
    "                        # Re-open since verify() closes the file\n",
    "                        buffer.seek(0)\n",
    "                        img = Image.open(buffer).convert('L')\n",
    "                        img_array = np.array(img)\n",
    "                        \n",
    "                        if self.testing:\n",
    "                            patches = self._extract_patches_test(img_array)\n",
    "                        else:\n",
    "                            patches = self._extract_patches(img_array)\n",
    "                            patches = [augmentation_pipeline(patch) for patch in patches]\n",
    "                        \n",
    "                        # Clean memory\n",
    "                        del img, img_array, buffer, image_bytes\n",
    "                        \n",
    "                        return patches, label\n",
    "                    \n",
    "                    except (OSError, IOError, ValueError) as e:\n",
    "                        print(f\"Warning: Corrupt BCF image at index {bcf_idx}: {e}\")\n",
    "                        return [], -1\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error processing idx {idx}: {e}\")\n",
    "            \n",
    "            # If we got here, there was an issue with this index - try a different one\n",
    "            # Important: increment as an integer, not trying to add to a list\n",
    "            if retry < max_retries - 1:  # Only increment if we have retries left\n",
    "                idx = (int(idx) + 1) % len(self)\n",
    "        \n",
    "        # If all retries failed, return empty\n",
    "        return [], -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63ed86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.139497Z",
     "iopub.status.busy": "2025-05-20T17:54:51.139225Z",
     "iopub.status.idle": "2025-05-20T17:54:51.151180Z",
     "shell.execute_reply": "2025-05-20T17:54:51.150622Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.020437,
     "end_time": "2025-05-20T17:54:51.152248",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.131811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# memory_efficient_patch_collate_fn\n",
    "import gc\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "# Add this memory-efficient patch collate function\n",
    "def memory_efficient_patch_collate_fn(batch, patch_size_tuple):\n",
    "    \"\"\"\n",
    "    Memory-efficient version of patch_collate_fn that processes one patch at a time\n",
    "    and includes robust error handling.\n",
    "    \"\"\"\n",
    "    import gc  # Import inside function for worker processes\n",
    "    \n",
    "    all_patches = []\n",
    "    all_labels = []\n",
    "    valid_batch_items = 0\n",
    "\n",
    "    # Process one item at a time to avoid large memory allocations\n",
    "    for item in batch:\n",
    "        patches, label = item\n",
    "        # Ensure item is valid\n",
    "        if patches and label != -1:\n",
    "            # Process patches one by one\n",
    "            for patch in patches:\n",
    "                all_patches.append(patch)\n",
    "                all_labels.append(label)\n",
    "            valid_batch_items += 1\n",
    "    \n",
    "    # Periodically force garbage collection\n",
    "    if len(all_patches) > 100:\n",
    "        gc.collect()\n",
    "    \n",
    "    # Empty batch handling\n",
    "    if not all_patches:\n",
    "        patch_h, patch_w = patch_size_tuple\n",
    "        return torch.empty((0, 1, patch_h, patch_w), dtype=torch.float), torch.empty((0,), dtype=torch.long)\n",
    "\n",
    "    # Process in smaller chunks to reduce peak memory usage\n",
    "    max_chunk_size = 64  # Adjust based on your GPU memory\n",
    "    num_patches = len(all_patches)\n",
    "    patches_tensor_list = []\n",
    "    \n",
    "    for i in range(0, num_patches, max_chunk_size):\n",
    "        chunk = all_patches[i:i+max_chunk_size]\n",
    "        # Convert to NumPy array\n",
    "        chunk_np = np.stack(chunk)\n",
    "        # Convert to tensor, normalize and add channel dimension\n",
    "        chunk_tensor = torch.from_numpy(chunk_np).float() / 255.0\n",
    "        chunk_tensor = chunk_tensor.unsqueeze(1)\n",
    "        patches_tensor_list.append(chunk_tensor)\n",
    "        \n",
    "        # Clear variables to free memory\n",
    "        del chunk, chunk_np\n",
    "    \n",
    "    # Concatenate chunks\n",
    "    patches_tensor = torch.cat(patches_tensor_list, dim=0)\n",
    "    labels_tensor = torch.tensor(all_labels, dtype=torch.long)\n",
    "    \n",
    "    # Clean up\n",
    "    del patches_tensor_list, all_patches, all_labels\n",
    "    gc.collect()\n",
    "    \n",
    "    return patches_tensor, labels_tensor\n",
    "\n",
    "# Add this function to create optimized DataLoaders\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "def create_optimized_dataloaders(dataset, batch_size=512, num_workers=2, val_split=0.1):\n",
    "    \"\"\"\n",
    "    Creates DataLoaders with proper error handling, avoiding HuggingFace datasets compatibility issues.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The image dataset instance\n",
    "        batch_size: Batch size for training\n",
    "        num_workers: Number of worker processes\n",
    "        val_split: Validation split ratio (0-1)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader)\n",
    "    \"\"\"\n",
    "    from torch.utils.data import DataLoader, Subset\n",
    "    import numpy as np\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.arange(dataset_size)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    split_idx = int(np.floor(val_split * dataset_size))\n",
    "    train_indices, val_indices = indices[split_idx:], indices[:split_idx]\n",
    "    \n",
    "    # Create subset datasets - this avoids Hugging Face's __getitems__ implementation\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    # Custom collate function with error handling\n",
    "    def safe_collate(batch):\n",
    "        # Filter out empty or invalid items\n",
    "        valid_batch = [(patches, label) for patches, label in batch if patches and label != -1]\n",
    "        \n",
    "        if not valid_batch:\n",
    "            # Return empty tensors if no valid items\n",
    "            return torch.empty((0, 1, 105, 105)), torch.empty((0,), dtype=torch.long)\n",
    "        \n",
    "        # Process valid items\n",
    "        all_patches = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for patches, label in valid_batch:\n",
    "            if isinstance(patches, list) and patches:\n",
    "                all_patches.extend(patches)\n",
    "                all_labels.extend([label] * len(patches))\n",
    "        \n",
    "        if not all_patches:\n",
    "            return torch.empty((0, 1, 105, 105)), torch.empty((0,), dtype=torch.long)\n",
    "            \n",
    "        # Convert to PyTorch tensors\n",
    "        try:\n",
    "            patches_np = np.array(all_patches)\n",
    "            patches_tensor = torch.tensor(patches_np, dtype=torch.float) / 255.0\n",
    "            \n",
    "            # Add channel dimension if needed\n",
    "            if len(patches_tensor.shape) == 3:  # (B, H, W)\n",
    "                patches_tensor = patches_tensor.unsqueeze(1)  # -> (B, 1, H, W)\n",
    "                \n",
    "            labels_tensor = torch.tensor(all_labels, dtype=torch.long)\n",
    "            return patches_tensor, labels_tensor\n",
    "        except Exception as e:\n",
    "            print(f\"Error in collate function: {e}\")\n",
    "            return torch.empty((0, 1, 105, 105)), torch.empty((0,), dtype=torch.long)\n",
    "    \n",
    "    # Create DataLoaders with minimal worker configuration for stability\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=safe_collate,\n",
    "        pin_memory=False,\n",
    "        persistent_workers=True if num_workers > 0 else False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=safe_collate,\n",
    "        pin_memory=False,\n",
    "        persistent_workers=True if num_workers > 0 else False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2873d84a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.166635Z",
     "iopub.status.busy": "2025-05-20T17:54:51.166000Z",
     "iopub.status.idle": "2025-05-20T17:54:51.172928Z",
     "shell.execute_reply": "2025-05-20T17:54:51.172378Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015261,
     "end_time": "2025-05-20T17:54:51.173996",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.158735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collate functions\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of tuples (patches_list, label)\n",
    "      - patches_list: list of P numpy arrays of shape (H, W) or (H, W, C)\n",
    "      - label: int\n",
    "    Returns:\n",
    "      - images: Tensor of shape (B, P, C, H, W)\n",
    "      - labels: Tensor of shape (B,)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for patches_list, label in batch:\n",
    "        patch_tensors = []\n",
    "        for patch in patches_list:\n",
    "            # patch is a numpy array\n",
    "            arr = patch\n",
    "            # grayscale or RGB?\n",
    "            if arr.ndim == 2:\n",
    "                # (H, W) → (1, H, W)\n",
    "                t = torch.from_numpy(arr).unsqueeze(0)\n",
    "            else:\n",
    "                # (H, W, C) → (C, H, W)\n",
    "                t = torch.from_numpy(arr).permute(2, 0, 1)\n",
    "            # normalize to [0,1] float\n",
    "            t = t.float().div(255.0)\n",
    "            patch_tensors.append(t)\n",
    "        # stack P patches → (P, C, H, W)\n",
    "        images.append(torch.stack(patch_tensors, dim=0))\n",
    "        labels.append(label)\n",
    "    # now batch them → (B, P, C, H, W) and (B,)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return images, labels\n",
    "    \n",
    "def train_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of (patches_list, label) where\n",
    "      patches_list: list of P numpy arrays, each H×W or H×W×C\n",
    "      label: int\n",
    "    Returns:\n",
    "      images: Tensor of shape (B*P, C, H, W)\n",
    "      labels: Tensor of shape (B*P,)\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    lbls = []\n",
    "    for patches, label in batch:\n",
    "        for patch in patches:\n",
    "            arr = patch\n",
    "            # to torch tensor: (H,W)→(1,H,W), (H,W,C)→(C,H,W)\n",
    "            if arr.ndim == 2:\n",
    "                t = torch.from_numpy(arr).unsqueeze(0)\n",
    "            else:\n",
    "                t = torch.from_numpy(arr).permute(2, 0, 1)\n",
    "            # normalize to [0,1]\n",
    "            imgs.append(t.float().div(255.0))\n",
    "            lbls.append(label)\n",
    "    images = torch.stack(imgs, dim=0)\n",
    "    labels = torch.tensor(lbls, dtype=torch.long)\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8240ef59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.187677Z",
     "iopub.status.busy": "2025-05-20T17:54:51.187480Z",
     "iopub.status.idle": "2025-05-20T17:54:51.191726Z",
     "shell.execute_reply": "2025-05-20T17:54:51.191192Z"
    },
    "papermill": {
     "duration": 0.012164,
     "end_time": "2025-05-20T17:54:51.192737",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.180573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save and load dataset\n",
    "import pickle\n",
    "\n",
    "def save_dataset(dataset, filepath: str):\n",
    "    \"\"\"\n",
    "    Serialize and save a CombinedImageDataset to disk.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "    print(f\"Dataset saved to {filepath!r}\")\n",
    "\n",
    "def load_dataset(filepath: str):\n",
    "    \"\"\"\n",
    "    Load a pickled CombinedImageDataset from disk.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    print(f\"Dataset loaded from {filepath!r}\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02214dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.206655Z",
     "iopub.status.busy": "2025-05-20T17:54:51.206459Z",
     "iopub.status.idle": "2025-05-20T17:54:51.209549Z",
     "shell.execute_reply": "2025-05-20T17:54:51.208985Z"
    },
    "papermill": {
     "duration": 0.011447,
     "end_time": "2025-05-20T17:54:51.210630",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.199183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# synthetic_dataset = load_dataset(\"/kaggle/input/font-datasets/synthetic_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9881195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.224619Z",
     "iopub.status.busy": "2025-05-20T17:54:51.224388Z",
     "iopub.status.idle": "2025-05-20T17:54:51.229582Z",
     "shell.execute_reply": "2025-05-20T17:54:51.229060Z"
    },
    "papermill": {
     "duration": 0.013519,
     "end_time": "2025-05-20T17:54:51.230656",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.217137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Visualization some samples from the combined dataset \n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from PIL import Image, ImageFile\n",
    "# from io import BytesIO\n",
    "# import os\n",
    "\n",
    "# def visualize_simple_images_and_patches(dataset, num_images=2, seed=None):\n",
    "#     # Allow loading of truncated images\n",
    "#     ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    \n",
    "#     # Set random seed if provided\n",
    "#     if seed is not None:\n",
    "#         random.seed(seed)\n",
    "    \n",
    "#     # Find valid images (with patches)\n",
    "#     valid_indices = []\n",
    "#     attempts = 0\n",
    "#     max_attempts = min(len(dataset) * 2, 100)  # Limit search attempts\n",
    "    \n",
    "#     while len(valid_indices) < num_images and attempts < max_attempts:\n",
    "#         idx = random.randint(0, len(dataset) - 1)\n",
    "#         if idx not in valid_indices:  # Avoid duplicates\n",
    "#             try:\n",
    "#                 patches, label = dataset[idx]\n",
    "#                 if patches and len(patches) > 0:\n",
    "#                     valid_indices.append(idx)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error loading index {idx}: {e}\")\n",
    "#             attempts += 1\n",
    "    \n",
    "#     # If we couldn't find enough valid images\n",
    "#     if len(valid_indices) < num_images:\n",
    "#         print(f\"Warning: Could only find {len(valid_indices)} valid images with patches\")\n",
    "#         if len(valid_indices) == 0:\n",
    "#             print(\"No valid images found. Check your dataset.\")\n",
    "#             return\n",
    "    \n",
    "#     # Create figure with enough space for all elements\n",
    "#     fig, axes = plt.subplots(len(valid_indices), 4, figsize=(16, 5 * len(valid_indices)))\n",
    "    \n",
    "#     # If only one image is requested, make axes indexable as 2D\n",
    "#     if len(valid_indices) == 1:\n",
    "#         axes = axes.reshape(1, -1)\n",
    "    \n",
    "#     for i, idx in enumerate(valid_indices):\n",
    "#         try:\n",
    "#             # Get item directly from dataset\n",
    "#             patches, label = dataset[idx]\n",
    "            \n",
    "#             # Get the original full image\n",
    "#             img_array = None\n",
    "            \n",
    "#             if hasattr(dataset, 'jpeg_data') and idx < len(dataset.jpeg_data):\n",
    "#                 # From jpeg_data\n",
    "#                 img_path, _ = dataset.jpeg_data[idx]\n",
    "#                 img = Image.open(img_path).convert('L')\n",
    "#                 img_array = np.array(img)\n",
    "#                 source = f\"JPEG file: {os.path.basename(img_path)}\"\n",
    "                \n",
    "#             elif hasattr(dataset, 'image_filenames') and not hasattr(dataset, 'num_images'):\n",
    "#                 # From BCFImagePatchDataset with JPEG source\n",
    "#                 img_path = os.path.join(dataset.data_source, dataset.image_filenames[idx])\n",
    "#                 img = Image.open(img_path).convert('L')\n",
    "#                 img_array = np.array(img)\n",
    "#                 source = f\"JPEG file: {dataset.image_filenames[idx]}\"\n",
    "                \n",
    "#             else:\n",
    "#                 # From BCF file (either CombinedImageDataset or BCFImagePatchDataset)\n",
    "#                 if hasattr(dataset, 'bcf_data'):\n",
    "#                     # CombinedImageDataset\n",
    "#                     bcf_idx = idx - len(dataset.jpeg_data)\n",
    "#                     if bcf_idx < 0 or bcf_idx >= len(dataset.bcf_data):\n",
    "#                         print(f\"Invalid BCF index: {bcf_idx}\")\n",
    "#                         continue\n",
    "                        \n",
    "#                     offset = dataset.image_offsets[bcf_idx]\n",
    "#                     size = dataset.image_sizes[bcf_idx]\n",
    "#                     data_file = dataset.bcf_file\n",
    "#                     data_start = dataset.data_start_offset\n",
    "#                     source = f\"BCF file (idx: {bcf_idx})\"\n",
    "#                 else:\n",
    "#                     # BCFImagePatchDataset\n",
    "#                     offset = dataset.image_offsets[idx]\n",
    "#                     size = dataset.image_sizes[idx]\n",
    "#                     data_file = dataset.data_source\n",
    "#                     data_start = dataset.data_start_offset\n",
    "#                     source = f\"BCF file (idx: {idx})\"\n",
    "                \n",
    "#                 with open(data_file, 'rb') as f:\n",
    "#                     f.seek(data_start + offset)\n",
    "#                     image_bytes = f.read(size)\n",
    "#                 img = Image.open(BytesIO(image_bytes)).convert('L')\n",
    "#                 img_array = np.array(img)\n",
    "            \n",
    "#             # Plot original image if we successfully loaded it\n",
    "#             if img_array is not None:\n",
    "#                 axes[i, 0].imshow(img_array, cmap='gray')\n",
    "#                 axes[i, 0].set_title(f\"Original Image\\nLabel: {label}\\nSource: {source}\")\n",
    "#                 axes[i, 0].axis('off')\n",
    "#             else:\n",
    "#                 axes[i, 0].text(0.5, 0.5, \"Image loading failed\", ha='center', va='center')\n",
    "#                 axes[i, 0].axis('off')\n",
    "            \n",
    "#             # Plot the patches - ensure we have patches to display\n",
    "#             if patches and len(patches) > 0:\n",
    "#                 for j in range(3):\n",
    "#                     if j < len(patches):\n",
    "#                         patch = patches[j]\n",
    "#                         axes[i, j+1].imshow(patch, cmap='gray')\n",
    "#                         axes[i, j+1].set_title(f\"Patch {j+1}\\nShape: {patch.shape}\")\n",
    "#                     else:\n",
    "#                         # No more patches to display\n",
    "#                         axes[i, j+1].text(0.5, 0.5, \"No patch\", ha='center', va='center')\n",
    "#                     axes[i, j+1].axis('off')\n",
    "#             else:\n",
    "#                 # No patches for this image\n",
    "#                 for j in range(3):\n",
    "#                     axes[i, j+1].text(0.5, 0.5, \"No patches extracted\", ha='center', va='center')\n",
    "#                     axes[i, j+1].axis('off')\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing index {idx}: {e}\")\n",
    "#             # Create error message in subplot\n",
    "#             for j in range(4):\n",
    "#                 axes[i, j].text(0.5, 0.5, f\"Error: {str(e)[:50]}...\", ha='center', va='center')\n",
    "#                 axes[i, j].axis('off')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Return the indices we used (helpful for debugging)\n",
    "#     return valid_indices\n",
    "\n",
    "# # Example usage:\n",
    "# visualize_simple_images_and_patches(synthetic_dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f24d0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.244408Z",
     "iopub.status.busy": "2025-05-20T17:54:51.244171Z",
     "iopub.status.idle": "2025-05-20T17:54:51.246954Z",
     "shell.execute_reply": "2025-05-20T17:54:51.246482Z"
    },
    "papermill": {
     "duration": 0.010814,
     "end_time": "2025-05-20T17:54:51.248024",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.237210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(synthetic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e860c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.261600Z",
     "iopub.status.busy": "2025-05-20T17:54:51.261395Z",
     "iopub.status.idle": "2025-05-20T17:54:51.515084Z",
     "shell.execute_reply": "2025-05-20T17:54:51.513836Z"
    },
    "papermill": {
     "duration": 0.262075,
     "end_time": "2025-05-20T17:54:51.516477",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.254402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: JPEG directory jpeg_dir does not exist.\n",
      "Loaded 200000 labels from /kaggle/input/deepfont-unlab/syn_train/VFR_syn_train_extracted.label.\n",
      "Loaded 200000 images from /kaggle/input/deepfont-unlab/syn_train/VFR_syn_train_extracted.bcf.\n",
      "Loaded 200000 .bcf images.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Clean memory before starting\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "jpeg_dir = \"/kaggle/input/deepfont-unlab/scrape-wtf-new/scrape-wtf-new\"\n",
    "bcf_file = \"/kaggle/input/deepfont-unlab/syn_train/VFR_syn_train_extracted.bcf\"\n",
    "label_file = \"/kaggle/input/deepfont-unlab/syn_train/VFR_syn_train_extracted.label\"\n",
    "\n",
    "# Create dataset with smaller patch size and fewer patches per image\n",
    "synthetic_dataset = ImageDataset(\n",
    "    jpeg_dir=\"jpeg_dir\",\n",
    "    bcf_file=bcf_file,\n",
    "    label_file=label_file,\n",
    "    # testing=True,\n",
    "    num_patch=3,  # Number of patches per image\n",
    ")\n",
    "# save_dataset(test_dataset, \"/kaggle/working/test_datasets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d558b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.531038Z",
     "iopub.status.busy": "2025-05-20T17:54:51.530801Z",
     "iopub.status.idle": "2025-05-20T17:54:51.533831Z",
     "shell.execute_reply": "2025-05-20T17:54:51.533273Z"
    },
    "papermill": {
     "duration": 0.01146,
     "end_time": "2025-05-20T17:54:51.534919",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.523459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_dataset(synthetic_dataset, \"/kaggle/working/synthetic_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b602d51a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.549570Z",
     "iopub.status.busy": "2025-05-20T17:54:51.549070Z",
     "iopub.status.idle": "2025-05-20T17:54:51.587338Z",
     "shell.execute_reply": "2025-05-20T17:54:51.586621Z"
    },
    "papermill": {
     "duration": 0.04687,
     "end_time": "2025-05-20T17:54:51.588479",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.541609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 180000,  Eval samples: 20000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# combined_dataset = load_dataset(\"/kaggle/working/combined_dataset.pkl\")\n",
    "\n",
    "dataset = synthetic_dataset\n",
    "# 1. Decide split sizes\n",
    "total = len(dataset)\n",
    "train_size = int(0.9 * total)\n",
    "val_size   = total - train_size\n",
    "\n",
    "# 2. Split with a fixed seed for reproducibility\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)},  Eval samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c96f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.602887Z",
     "iopub.status.busy": "2025-05-20T17:54:51.602662Z",
     "iopub.status.idle": "2025-05-20T17:54:51.606882Z",
     "shell.execute_reply": "2025-05-20T17:54:51.606180Z"
    },
    "papermill": {
     "duration": 0.012642,
     "end_time": "2025-05-20T17:54:51.607921",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.595279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_collate_fn # test_collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d64cb22e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:51.621954Z",
     "iopub.status.busy": "2025-05-20T17:54:51.621534Z",
     "iopub.status.idle": "2025-05-20T17:54:54.719177Z",
     "shell.execute_reply": "2025-05-20T17:54:54.718173Z"
    },
    "papermill": {
     "duration": 3.106293,
     "end_time": "2025-05-20T17:54:54.720807",
     "exception": false,
     "start_time": "2025-05-20T17:54:51.614514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: torch.Size([192, 1, 105, 105]), Labels size: torch.Size([192])\n"
     ]
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "    images, labels = batch\n",
    "    print(f\"Batch size: {images.size()}, Labels size: {labels.size()}\")\n",
    "    break  # Just check the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f11d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:54.736144Z",
     "iopub.status.busy": "2025-05-20T17:54:54.735855Z",
     "iopub.status.idle": "2025-05-20T17:54:54.742630Z",
     "shell.execute_reply": "2025-05-20T17:54:54.741723Z"
    },
    "papermill": {
     "duration": 0.015772,
     "end_time": "2025-05-20T17:54:54.743727",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.727955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 200\n",
      "Labels: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# synthetic_dataset = load_dataset(\"/kaggle/input/font-datasets/synthetic_dataset.pkl\")\n",
    "filtered = synthetic_dataset\n",
    "unique_labels = np.unique(filtered.labels)\n",
    "\n",
    "print(f\"Number of unique labels: {unique_labels.size}\")\n",
    "print(f\"Labels: {unique_labels}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba7d7a",
   "metadata": {
    "papermill": {
     "duration": 0.006457,
     "end_time": "2025-05-20T17:54:54.756944",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.750487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SCAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb57e502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:54.771411Z",
     "iopub.status.busy": "2025-05-20T17:54:54.771126Z",
     "iopub.status.idle": "2025-05-20T17:54:54.787040Z",
     "shell.execute_reply": "2025-05-20T17:54:54.786468Z"
    },
    "papermill": {
     "duration": 0.024673,
     "end_time": "2025-05-20T17:54:54.788177",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.763504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_memory_efficient_model\n",
    "\n",
    "import torch.cuda.amp as amp\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_memory_efficient_model(model, train_loader, val_loader=None, \n",
    "                                num_epochs=5, learning_rate=0.0001,\n",
    "                                checkpoint_dir=\"/kaggle/working/\"):\n",
    "    \"\"\"\n",
    "    Memory-efficient training function for SCAE model.\n",
    "    \"\"\"\n",
    "    # Ensure checkpoint directory exists\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Setup device and optimization tools\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training on {device} with {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/1e9:.2f} GB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved(0)/1e9:.2f} GB\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Set up mixed precision training\n",
    "    scaler = amp.GradScaler()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    # Track best model\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            # Clean memory before each epoch\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # TRAINING PHASE\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            valid_batches = 0\n",
    "            \n",
    "            # Use tqdm for progress tracking\n",
    "            pbar = tqdm(train_loader)\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "            \n",
    "            for batch_idx, (patches, _) in enumerate(pbar):\n",
    "                # Skip empty batches\n",
    "                if patches.numel() == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Move data to device\n",
    "                patches = patches.to(device, non_blocking=True)\n",
    "                \n",
    "                # Mixed precision forward pass\n",
    "                with amp.autocast():\n",
    "                    outputs = model(patches)\n",
    "                    loss = criterion(outputs, patches)\n",
    "                \n",
    "                # Backward pass with gradient scaling\n",
    "                optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                # Update metrics\n",
    "                running_loss += loss.item()\n",
    "                valid_batches += 1\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "                \n",
    "                # Aggressive memory cleanup every few batches\n",
    "                if batch_idx % 10 == 0:\n",
    "                    del outputs, loss, patches\n",
    "                    gc.collect()\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "            \n",
    "            # Calculate epoch metrics\n",
    "            if valid_batches > 0:\n",
    "                train_loss = running_loss / valid_batches\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}\")\n",
    "            else:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, No valid batches!\")\n",
    "                continue\n",
    "                \n",
    "            # Save checkpoint every epoch\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, f\"{checkpoint_dir}/model_epoch_{epoch+1}.pt\")\n",
    "            \n",
    "            # VALIDATION PHASE\n",
    "            if val_loader:\n",
    "                val_loss = validate_memory_efficient(model, val_loader, criterion, device)\n",
    "                scheduler.step(val_loss)\n",
    "                \n",
    "                # Early stopping logic\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                    torch.save(model.state_dict(), f\"{checkpoint_dir}/best_model.pt\")\n",
    "                    print(f\"New best model saved with val_loss: {val_loss:.6f}\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= 3:  # Adjust patience as needed\n",
    "                        print(\"Early stopping triggered!\")\n",
    "                        break\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        # Save emergency checkpoint\n",
    "        torch.save(model.state_dict(), f\"{checkpoint_dir}/emergency_model.pt\")\n",
    "        raise\n",
    "        \n",
    "    return model\n",
    "\n",
    "def validate_memory_efficient(model, val_loader, criterion, device):\n",
    "    \"\"\"Memory-efficient validation function.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    valid_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader)\n",
    "        pbar.set_description(f\"Validating\")\n",
    "        \n",
    "        for patches, _ in pbar:\n",
    "            if patches.numel() == 0:\n",
    "                continue\n",
    "                \n",
    "            patches = patches.to(device, non_blocking=True)\n",
    "            \n",
    "            # Using mixed precision even for validation\n",
    "            with amp.autocast():\n",
    "                outputs = model(patches)\n",
    "                loss = criterion(outputs, patches)\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "            valid_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "            \n",
    "            # Clean up\n",
    "            del outputs, patches, loss\n",
    "    \n",
    "    if valid_batches > 0:\n",
    "        val_loss = running_loss / valid_batches\n",
    "        print(f\"Validation Loss: {val_loss:.6f}\")\n",
    "        return val_loss\n",
    "    else:\n",
    "        print(\"No valid validation batches!\")\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45c344cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:54.802972Z",
     "iopub.status.busy": "2025-05-20T17:54:54.802736Z",
     "iopub.status.idle": "2025-05-20T17:54:54.811156Z",
     "shell.execute_reply": "2025-05-20T17:54:54.810642Z"
    },
    "papermill": {
     "duration": 0.017064,
     "end_time": "2025-05-20T17:54:54.812171",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.795107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCAE\n",
    "import torch.nn as nn\n",
    "class SCAE(nn.Module):\n",
    "    def __init__(self, normalization_type=\"batch_norm\", use_dropout=False, dropout_prob=0.3, activation=\"relu\"):\n",
    "        super(SCAE, self).__init__()\n",
    "\n",
    "        def norm_layer(num_features):\n",
    "            if normalization_type == \"batch_norm\":\n",
    "                return nn.BatchNorm2d(num_features)\n",
    "            elif normalization_type == \"group_norm\":\n",
    "                return nn.GroupNorm(num_groups=8, num_channels=num_features)\n",
    "            elif normalization_type == \"layer_norm\":\n",
    "                return nn.LayerNorm([num_features, 12, 12])  # Updated for 12x12 feature maps\n",
    "            else:\n",
    "                return nn.Identity()\n",
    "\n",
    "        def activation_layer():\n",
    "            return nn.LeakyReLU(inplace=True) if activation == \"leaky_relu\" else nn.ReLU(inplace=True)\n",
    "\n",
    "        def dropout_layer():\n",
    "            return nn.Dropout2d(dropout_prob) if use_dropout else nn.Identity()\n",
    "\n",
    "        # Encoder: Input 105x105 -> Output 12x12\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Layer 1: 105x105 -> 48x48\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=2, padding=0),\n",
    "            norm_layer(64),\n",
    "            activation_layer(),\n",
    "            dropout_layer(),\n",
    "            \n",
    "            # Layer 2: 48x48 -> 24x24\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Layer 3: 24x24 -> 24x24\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            norm_layer(128),\n",
    "            activation_layer(),\n",
    "            dropout_layer(),\n",
    "            \n",
    "            # Layer 4: 24x24 -> 12x12 (added to get 12x12 output)\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Decoder: Input 12x12 -> Output 105x105\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Layer 1: 12x12 -> 24x24\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            norm_layer(64),\n",
    "            activation_layer(),\n",
    "            dropout_layer(),\n",
    "            \n",
    "            # Layer 2: 24x24 -> 48x48\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            norm_layer(32),\n",
    "            activation_layer(),\n",
    "            dropout_layer(),\n",
    "            \n",
    "            # Layer 3: 48x48 -> 105x105 (with precise output size)\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=14, stride=2, padding=2, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through encoder\n",
    "        if x.size(1) == 3:\n",
    "            # Use standard RGB to grayscale conversion: 0.299*R + 0.587*G + 0.114*B\n",
    "            x = 0.299 * x[:, 0:1] + 0.587 * x[:, 1:2] + 0.114 * x[:, 2:3]\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            # print(x.shape)\n",
    "\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "            # print(x.shape)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb1bb87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:54.826489Z",
     "iopub.status.busy": "2025-05-20T17:54:54.826100Z",
     "iopub.status.idle": "2025-05-20T17:54:54.829232Z",
     "shell.execute_reply": "2025-05-20T17:54:54.828711Z"
    },
    "papermill": {
     "duration": 0.011519,
     "end_time": "2025-05-20T17:54:54.830295",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.818776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create model and train with memory optimization\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = SCAE().to(device)\n",
    "# trained_model = train_memory_efficient_model(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     num_epochs=5,\n",
    "#     learning_rate=0.0001\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d1f73ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:54.844556Z",
     "iopub.status.busy": "2025-05-20T17:54:54.843994Z",
     "iopub.status.idle": "2025-05-20T17:54:54.916721Z",
     "shell.execute_reply": "2025-05-20T17:54:54.916065Z"
    },
    "papermill": {
     "duration": 0.080917,
     "end_time": "2025-05-20T17:54:54.917822",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.836905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SCAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Identity()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Identity()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Identity()\n",
       "    (5): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Identity()\n",
       "    (10): ConvTranspose2d(32, 1, kernel_size=(14, 14), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (11): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load checkpoints\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1) Re-instantiate your model\n",
    "pretrained_scae = SCAE().to(device)\n",
    "\n",
    "# 2) Load the checkpoint dict\n",
    "ckpt = torch.load(\"/kaggle/input/font_models/pytorch/default/1/model_epoch_5.pt\", weights_only=True)\n",
    "\n",
    "# 3) Pull out and load the actual weights\n",
    "pretrained_scae.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "\n",
    "# 4) (Optional) if you saved epoch or optimizer state too:\n",
    "# start_epoch = ckpt[\"epoch\"] + 1\n",
    "# optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "\n",
    "pretrained_scae.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f76a5a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:54.984697Z",
     "iopub.status.busy": "2025-05-20T17:54:54.984411Z",
     "iopub.status.idle": "2025-05-20T17:54:54.987667Z",
     "shell.execute_reply": "2025-05-20T17:54:54.987126Z"
    },
    "papermill": {
     "duration": 0.06376,
     "end_time": "2025-05-20T17:54:54.988736",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.924976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate_reconstruction(model, val_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f2d4170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:55.003730Z",
     "iopub.status.busy": "2025-05-20T17:54:55.003501Z",
     "iopub.status.idle": "2025-05-20T17:54:55.006803Z",
     "shell.execute_reply": "2025-05-20T17:54:55.006117Z"
    },
    "papermill": {
     "duration": 0.012153,
     "end_time": "2025-05-20T17:54:55.007933",
     "exception": false,
     "start_time": "2025-05-20T17:54:54.995780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize_latent_space(model, val_loader, device, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5866f078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:55.022705Z",
     "iopub.status.busy": "2025-05-20T17:54:55.022500Z",
     "iopub.status.idle": "2025-05-20T17:54:55.028285Z",
     "shell.execute_reply": "2025-05-20T17:54:55.027745Z"
    },
    "papermill": {
     "duration": 0.014587,
     "end_time": "2025-05-20T17:54:55.029376",
     "exception": false,
     "start_time": "2025-05-20T17:54:55.014789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # evaluation\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from torchvision.utils import make_grid\n",
    "# from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "\n",
    "# # ——————————————————————————————————————————————\n",
    "# # 1) Reconstruction evaluation\n",
    "# # ——————————————————————————————————————————————\n",
    "\n",
    "# def evaluate_reconstruction(model, dataloader, device, num_samples=10, save_path=None):\n",
    "#     \"\"\"\n",
    "#     Compute MSE, SSIM, PSNR between inputs and auto‐encoder reconstructions.\n",
    "#     Also visualize num_samples side‐by‐side.\n",
    "#     Expects dataloader that yields (imgs, _), where imgs is (B,1,H,W) in [0,1].\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     total_mse = total_ssim = total_psnr = 0.0\n",
    "#     seen = 0\n",
    "#     vis_in, vis_re = [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for imgs, _ in dataloader:\n",
    "#             imgs = imgs.to(device)                  # (B,1,105,105)\n",
    "#             recons = model(imgs)                    # (B,1,105,105)\n",
    "\n",
    "#             # batch MSE\n",
    "#             mse_batch = torch.mean((recons - imgs) ** 2).item()\n",
    "#             total_mse += mse_batch * imgs.size(0)\n",
    "\n",
    "#             # to numpy [0,1]\n",
    "#             inp_np  = imgs.cpu().squeeze(1).numpy()\n",
    "#             rec_np  = recons.cpu().squeeze(1).numpy()\n",
    "#             B = inp_np.shape[0]\n",
    "\n",
    "#             for i in range(B):\n",
    "#                 if seen >= num_samples: break\n",
    "\n",
    "#                 im = inp_np[i]\n",
    "#                 rc = rec_np[i]\n",
    "#                 total_ssim += ssim(im, rc, data_range=1.0)\n",
    "#                 total_psnr += psnr(im, rc, data_range=1.0)\n",
    "\n",
    "#                 vis_in .append(imgs [i].cpu())\n",
    "#                 vis_re .append(recons[i].cpu())\n",
    "#                 seen += 1\n",
    "\n",
    "#             if seen >= num_samples:\n",
    "#                 break\n",
    "\n",
    "#     N = len(dataloader.dataset) if hasattr(dataloader.dataset, \"__len__\") else seen\n",
    "#     avg_mse  = total_mse / N\n",
    "#     avg_ssim = total_ssim / seen\n",
    "#     avg_psnr = total_psnr / seen\n",
    "\n",
    "#     print(f\"Reconstruction → MSE: {avg_mse:.4f}, SSIM: {avg_ssim:.4f}, PSNR: {avg_psnr:.2f} dB\")\n",
    "\n",
    "#     if vis_in:\n",
    "#         # interleave originals and reconstructions\n",
    "#         grid = make_grid([*vis_in[:seen], *vis_re[:seen]],\n",
    "#                          nrow= seen,\n",
    "#                          normalize=True, pad_value=1)\n",
    "#         plt.figure(figsize=(seen*2, 4))\n",
    "#         plt.imshow(grid.permute(1,2,0).numpy())\n",
    "#         plt.axis('off')\n",
    "#         plt.title(\"Originals (top) vs Reconstructions (bottom)\")\n",
    "#         if save_path:\n",
    "#             plt.savefig(f\"{save_path}/recon.png\", bbox_inches=\"tight\")\n",
    "#         plt.show()\n",
    "\n",
    "#     return {\"mse\":avg_mse, \"ssim\":avg_ssim, \"psnr\":avg_psnr}\n",
    "\n",
    "\n",
    "# # ——————————————————————————————————————————————\n",
    "# # 2) Latent extraction & generation\n",
    "# # ——————————————————————————————————————————————\n",
    "\n",
    "# def extract_latent_features(model, x):\n",
    "#     \"\"\"\n",
    "#     Runs x through the encoder only.\n",
    "#     x: (B,1,105,105)\n",
    "#     returns: z (B,128,12,12)\n",
    "#     \"\"\"\n",
    "#     return model.encoder(x)\n",
    "\n",
    "# def generate_from_latent(model, z):\n",
    "#     \"\"\"\n",
    "#     Runs z through the decoder only.\n",
    "#     z: (B,128,12,12)\n",
    "#     returns: recon (B,1,105,105)\n",
    "#     \"\"\"\n",
    "#     return model.decoder(z)\n",
    "\n",
    "\n",
    "# # ——————————————————————————————————————————————\n",
    "# # 3) t-SNE visualization of latent space\n",
    "# # ——————————————————————————————————————————————\n",
    "\n",
    "# def visualize_latent_space(model, dataloader, device, max_samples=500, save_path=None):\n",
    "#     \"\"\"\n",
    "#     Collects up to max_samples latent vectors, runs t-SNE, and plots.\n",
    "#     Expects dataloader yielding (imgs, labels) with imgs in [0,1].\n",
    "#     \"\"\"\n",
    "#     from sklearn.manifold import TSNE\n",
    "\n",
    "#     model.eval()\n",
    "#     zs, ys = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for imgs, labels in dataloader:\n",
    "#             if len(zs) >= max_samples: break\n",
    "#             imgs = imgs.to(device)\n",
    "#             z = extract_latent_features(model, imgs)         # (B,128,12,12)\n",
    "#             zflat = z.view(z.size(0), -1).cpu().numpy()      # (B, 128*12*12)\n",
    "#             zs.append(zflat)\n",
    "#             ys.append(labels.numpy())\n",
    "#         zs = np.vstack(zs)[:max_samples]\n",
    "#         ys = np.concatenate(ys)[:max_samples]\n",
    "\n",
    "#     tsne = TSNE(n_components=2, random_state=42)\n",
    "#     Z2 = tsne.fit_transform(zs)\n",
    "\n",
    "#     plt.figure(figsize=(8,6))\n",
    "#     plt.scatter(Z2[:,0], Z2[:,1], c=ys, cmap=\"tab10\", s=5, alpha=0.7)\n",
    "#     plt.colorbar(label=\"Class\")\n",
    "#     plt.title(\"t-SNE of SCAE Latent Space\")\n",
    "#     if save_path:\n",
    "#         plt.savefig(f\"{save_path}/tsne.png\", bbox_inches=\"tight\")\n",
    "#     plt.show()\n",
    "\n",
    "#     return Z2, ys\n",
    "\n",
    "\n",
    "# # ——————————————————————————————————————————————\n",
    "# # 4) Latent interpolation\n",
    "# # ——————————————————————————————————————————————\n",
    "\n",
    "# def interpolate_latent_space(model, dataloader, device, steps=10, save_path=None):\n",
    "#     \"\"\"\n",
    "#     Linearly interpolate between two latent codes and decode them.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     imgs = None\n",
    "#     # grab first two distinct samples\n",
    "#     with torch.no_grad():\n",
    "#         for x, _ in dataloader:\n",
    "#             if x.size(0) >= 2:\n",
    "#                 imgs = x[:2].to(device)\n",
    "#                 break\n",
    "#     if imgs is None:\n",
    "#         print(\"Not enough samples for interpolation\"); return\n",
    "\n",
    "#     z1 = extract_latent_features(model, imgs[0:1])   # (1,128,12,12)\n",
    "#     z2 = extract_latent_features(model, imgs[1:2])\n",
    "\n",
    "#     interps = []\n",
    "#     alphas = np.linspace(0,1,steps)\n",
    "#     for a in alphas:\n",
    "#         z = a*z1 + (1-a)*z2\n",
    "#         recon = generate_from_latent(model, z)        # (1,1,105,105)\n",
    "#         interps.append(recon.cpu())\n",
    "\n",
    "#     # build grid: [orig1, *interps, orig2]\n",
    "#     all_ = torch.cat([imgs[0:1].cpu(), *interps, imgs[1:2].cpu()], dim=0)\n",
    "#     grid = make_grid(all_, nrow=steps+2, normalize=True, pad_value=1)\n",
    "\n",
    "#     plt.figure(figsize=(12,3))\n",
    "#     plt.imshow(grid.permute(1,2,0).numpy())\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(\"Latent Interpolation\")\n",
    "#     if save_path:\n",
    "#         plt.savefig(f\"{save_path}/interp.png\", bbox_inches=\"tight\")\n",
    "#     plt.show()\n",
    "\n",
    "#     return interps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7d81220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:55.043643Z",
     "iopub.status.busy": "2025-05-20T17:54:55.043451Z",
     "iopub.status.idle": "2025-05-20T17:54:55.046400Z",
     "shell.execute_reply": "2025-05-20T17:54:55.045855Z"
    },
    "papermill": {
     "duration": 0.01136,
     "end_time": "2025-05-20T17:54:55.047516",
     "exception": false,
     "start_time": "2025-05-20T17:54:55.036156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !zip -r /kaggle/working/evaluation_results.zip /kaggle/working/evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e9aa8",
   "metadata": {
    "id": "1hbTCU2qndht",
    "papermill": {
     "duration": 0.006519,
     "end_time": "2025-05-20T17:54:55.060680",
     "exception": false,
     "start_time": "2025-05-20T17:54:55.054161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Font classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d84dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:55.075542Z",
     "iopub.status.busy": "2025-05-20T17:54:55.074885Z",
     "iopub.status.idle": "2025-05-20T17:54:55.083009Z",
     "shell.execute_reply": "2025-05-20T17:54:55.082510Z"
    },
    "papermill": {
     "duration": 0.016823,
     "end_time": "2025-05-20T17:54:55.084121",
     "exception": false,
     "start_time": "2025-05-20T17:54:55.067298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FontClassifier\n",
    "class FontClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_scae, num_classes=200, normalization_type=\"batch_norm\", \n",
    "                 use_dropout=False, dropout_prob=0.3, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.pretrained_scae = pretrained_scae  # Use pretrained SCAE encoder\n",
    "        \n",
    "        # Define helper functions for creating layers\n",
    "        def norm_layer(num_features, spatial_size=None):\n",
    "            if normalization_type == \"batch_norm\":\n",
    "                return nn.BatchNorm2d(num_features)\n",
    "            elif normalization_type == \"group_norm\":\n",
    "                return nn.GroupNorm(num_groups=8, num_channels=num_features)\n",
    "            elif normalization_type == \"layer_norm\" and spatial_size is not None:\n",
    "                return nn.LayerNorm([num_features, spatial_size, spatial_size])\n",
    "            else:\n",
    "                return nn.Identity()\n",
    "\n",
    "        def activation_layer():\n",
    "            return nn.LeakyReLU(inplace=True) if activation == \"leaky_relu\" else nn.ReLU(inplace=True)\n",
    "\n",
    "        def dropout_layer():\n",
    "            return nn.Dropout2d(dropout_prob) if use_dropout else nn.Identity()\n",
    "        \n",
    "        # CNN head after the SCAE encoder\n",
    "        # SCAE encoder output is 128 x 26 x 26\n",
    "        self.cnn_head = nn.Sequential(\n",
    "            # Conv layer 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  # Out: 256 x 12 x 12\n",
    "            norm_layer(256, 12),\n",
    "            activation_layer(),\n",
    "            \n",
    "            # Conv layer 5\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),  # Out: 256 x 12 x 12\n",
    "            norm_layer(256, 13),\n",
    "            activation_layer(),\n",
    "            dropout_layer()\n",
    "        )\n",
    "        \n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Input size is 256 * 12 * 12 = 43,264\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(256 * 12 * 12, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_prob if use_dropout else 0),\n",
    "            \n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_prob if use_dropout else 0),\n",
    "            \n",
    "            nn.Linear(2048, num_classes),\n",
    "            # nn.Softmax(dim=1) no softmax here bro, crossentropy does the softmax automatically\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the encoder part of SCAE\n",
    "        x = self.pretrained_scae.encoder(x)\n",
    "        # Continue with additional CNN layers\n",
    "        x = self.cnn_head(x)\n",
    "        \n",
    "        # Flatten and apply fully connected layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de99fd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:54:55.099043Z",
     "iopub.status.busy": "2025-05-20T17:54:55.098529Z",
     "iopub.status.idle": "2025-05-20T17:55:02.001811Z",
     "shell.execute_reply": "2025-05-20T17:55:02.000657Z"
    },
    "papermill": {
     "duration": 6.912508,
     "end_time": "2025-05-20T17:55:02.003538",
     "exception": false,
     "start_time": "2025-05-20T17:54:55.091030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 1, 105, 105])\n",
      "torch.Size([768, 200])\n"
     ]
    }
   ],
   "source": [
    "classifier = FontClassifier(pretrained_scae, num_classes=200).to(device)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch[0].shape)\n",
    "    print(classifier(batch[0].to(device)).shape)\n",
    "    # show_images_in_grid(batch.permute(0, 2, 3, 1).numpy(), titles=[f'Patch {i+1}' for i in range(len(batch))], cols=4)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f350e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:55:02.019008Z",
     "iopub.status.busy": "2025-05-20T17:55:02.018748Z",
     "iopub.status.idle": "2025-05-20T17:55:02.163759Z",
     "shell.execute_reply": "2025-05-20T17:55:02.162847Z"
    },
    "papermill": {
     "duration": 0.154115,
     "end_time": "2025-05-20T17:55:02.165158",
     "exception": false,
     "start_time": "2025-05-20T17:55:02.011043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/classifier_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8c445d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:55:02.181519Z",
     "iopub.status.busy": "2025-05-20T17:55:02.181229Z",
     "iopub.status.idle": "2025-05-20T17:55:02.315517Z",
     "shell.execute_reply": "2025-05-20T17:55:02.314687Z"
    },
    "papermill": {
     "duration": 0.144256,
     "end_time": "2025-05-20T17:55:02.316972",
     "exception": false,
     "start_time": "2025-05-20T17:55:02.172716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler=None,\n",
    "    device=\"cuda\",\n",
    "    num_epochs=5,\n",
    "    early_stopping_patience=None,\n",
    "    checkpoint_path=None,\n",
    "    use_amp=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic training loop for any (batch_size,1,105,105) ➔ (batch_size,num_classes) model.\n",
    "    \n",
    "    Args:\n",
    "        model:         nn.Module that maps inputs ➔ logits\n",
    "        train_loader:  DataLoader for training\n",
    "        val_loader:    DataLoader for validation\n",
    "        optimizer:     torch.optim.Optimizer\n",
    "        criterion:     loss function (e.g. nn.CrossEntropyLoss())\n",
    "        scheduler:     learning-rate scheduler (optional)\n",
    "        device:        'cuda' or 'cpu'\n",
    "        num_epochs:    number of epochs\n",
    "        early_stopping_patience: stop if no val-loss improvement for this many epochs (optional)\n",
    "        checkpoint_path: path to save best model state_dict (optional)\n",
    "        use_amp:       whether to use mixed precision (bool)\n",
    "    \n",
    "    Returns:\n",
    "        model:         best model (weights restored from checkpoint if provided)\n",
    "        history:       dict with lists: train_loss, train_acc, val_loss, val_acc\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    scaler = GradScaler() if use_amp and device != \"cpu\" else None\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [], \"train_acc\": [],\n",
    "        \"val_loss\":   [], \"val_acc\":   []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # ——— Training ————————————————————————————————\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"[Epoch {epoch}/{num_epochs}] Train\", leave=False)\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    logits = model(inputs)\n",
    "                    loss = criterion(logits, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # metrics\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            running_total   += labels.size(0)\n",
    "            pbar.set_postfix(loss=running_loss/running_total, acc=100.*running_correct/running_total)\n",
    "\n",
    "        train_loss = running_loss / running_total\n",
    "        train_acc  = 100. * running_correct / running_total\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "\n",
    "        # ——— Validation ———————————————————————————————\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total   = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc=f\"[Epoch {epoch}/{num_epochs}] Val  \", leave=False)\n",
    "            for inputs, labels in pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        logits = model(inputs)\n",
    "                        loss = criterion(logits, labels)\n",
    "                else:\n",
    "                    logits = model(inputs)\n",
    "                    loss = criterion(logits, labels)\n",
    "\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total   += labels.size(0)\n",
    "                pbar.set_postfix(val_loss=val_loss/val_total, val_acc=100.*val_correct/val_total)\n",
    "\n",
    "        val_loss_epoch = val_loss / val_total\n",
    "        val_acc_epoch  = 100. * val_correct / val_total\n",
    "        history[\"val_loss\"].append(val_loss_epoch)\n",
    "        history[\"val_acc\"].append(val_acc_epoch)\n",
    "\n",
    "        # ——— Scheduler step ————————————————————————————\n",
    "        if scheduler is not None:\n",
    "            # if ReduceLROnPlateau, pass val_loss\n",
    "            if hasattr(scheduler, \"step\") and scheduler.__class__.__name__ == \"ReduceLROnPlateau\":\n",
    "                scheduler.step(val_loss_epoch)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        # ——— Checkpoint & Early Stopping —————————————————————\n",
    "        if checkpoint_path is not None and val_loss_epoch < best_val_loss:\n",
    "            best_val_loss = val_loss_epoch\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            epochs_no_improve = 0\n",
    "            print(f\"→ New best model saved (val_loss={best_val_loss:.4f})\")\n",
    "        elif early_stopping_patience is not None:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                print(f\"→ Early stopping after {epoch} epochs without improvement.\")\n",
    "                break\n",
    "\n",
    "        # summary print\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs} \"\n",
    "            f\"Train: loss={train_loss:.4f}, acc={train_acc:.2f}% | \"\n",
    "            f\"Val: loss={val_loss_epoch:.4f}, acc={val_acc_epoch:.2f}%\"\n",
    "        )\n",
    "\n",
    "    # reload best weights if checkpoint was used\n",
    "    if checkpoint_path is not None and os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e2620d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:55:02.333038Z",
     "iopub.status.busy": "2025-05-20T17:55:02.332759Z",
     "iopub.status.idle": "2025-05-20T17:55:02.341605Z",
     "shell.execute_reply": "2025-05-20T17:55:02.340924Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018019,
     "end_time": "2025-05-20T17:55:02.342807",
     "exception": false,
     "start_time": "2025-05-20T17:55:02.324788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate(model, test_loader, device='cuda', use_amp=False):\n",
    "    \"\"\"\n",
    "    Testing-phase: aggregates 15 patches per sample, computes loss + top1/top5 metrics.\n",
    "    Returns (top1_error, top5_error).\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct1 = 0\n",
    "    correct5 = 0\n",
    "\n",
    "    test_pbar = tqdm(\n",
    "        total=len(test_loader),\n",
    "        desc=\"Testing\",\n",
    "        unit=\"batch\",\n",
    "        leave=True,\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # inputs: [B, P, C, H, W]\n",
    "            B, P, C, H, W = inputs.shape\n",
    "            inputs = inputs.view(B*P, C, H, W).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward all patches\n",
    "            if use_amp and device != 'cpu':\n",
    "                with autocast():\n",
    "                    logits = model(inputs)\n",
    "            else:\n",
    "                logits = model(inputs)\n",
    "\n",
    "            # Reshape + average over patches → [B, num_classes]\n",
    "            num_classes = logits.size(1)\n",
    "            avg_logits = logits.view(B, P, num_classes).mean(dim=1)\n",
    "\n",
    "            # Compute loss on averaged logits\n",
    "            loss = criterion(avg_logits, labels)\n",
    "            total_loss += loss.item() * B\n",
    "\n",
    "            # Top-1\n",
    "            _, pred1 = avg_logits.max(1)\n",
    "            correct1 += pred1.eq(labels).sum().item()\n",
    "\n",
    "            # Top-5\n",
    "            _, pred5 = avg_logits.topk(5, dim=1, largest=True, sorted=True)\n",
    "            correct5 += (pred5 == labels.view(-1, 1)).any(dim=1).sum().item()\n",
    "\n",
    "            total_samples += B\n",
    "\n",
    "            test_pbar.set_postfix({\n",
    "                'loss':    f\"{loss.item():.4f}\",\n",
    "                'top1_acc': f\"{100.*correct1/total_samples:.2f}%\",\n",
    "                'top5_acc': f\"{100.*correct5/total_samples:.2f}%\"\n",
    "            })\n",
    "            test_pbar.update()\n",
    "\n",
    "    test_pbar.close()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    top1_acc = 100. * correct1 / total_samples\n",
    "    top5_acc = 100. * correct5 / total_samples\n",
    "\n",
    "    print(f\"\\nTest Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Top-1 Accuracy: {top1_acc:.2f}% | Top-1 Error: {100.-top1_acc:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy: {top5_acc:.2f}% | Top-5 Error: {100.-top5_acc:.2f}%\")\n",
    "\n",
    "    return 100. - top1_acc, 100. - top5_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "452640ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T17:55:02.358652Z",
     "iopub.status.busy": "2025-05-20T17:55:02.358207Z",
     "iopub.status.idle": "2025-05-20T18:27:13.866069Z",
     "shell.execute_reply": "2025-05-20T18:27:13.865161Z"
    },
    "papermill": {
     "duration": 1931.517391,
     "end_time": "2025-05-20T18:27:13.867656",
     "exception": false,
     "start_time": "2025-05-20T17:55:02.350265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de93ca3077e46399c1ed006b0964a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 1/5] Train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649f6d3635654b9fb0718aa231b21f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 1/5] Val  :   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ New best model saved (val_loss=0.7719)\n",
      "Epoch 1/5 Train: loss=1.5540, acc=56.80% | Val: loss=0.7719, acc=75.47%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635ca6813b044c45808e21fdef73017c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 2/5] Train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "      Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> \n",
      " Traceback (most recent call last):\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "     ^^self._shutdown_workers()^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^    ^if w.is_alive():^\n",
      "^ ^ ^ ^ ^^ ^ ^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> \n",
      "^^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^    ^^self._shutdown_workers()^^^\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^    ^^if w.is_alive():^^^\n",
      "^\n",
      " ^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "     ^assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      " \n",
      " AssertionError :    can only test a child process^ \n",
      " ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^  ^  ^^ ^^ ^ ^^ ^ ^ ^ ^^^^^^^^^^^\n",
      "^AssertionError^: can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ede76a509c94d15adecf7890f745aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 2/5] Val  :   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ New best model saved (val_loss=0.4724)\n",
      "Epoch 2/5 Train: loss=0.5695, acc=81.63% | Val: loss=0.4724, acc=84.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c698fc66b754f6daf0f135e0220323c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 3/5] Train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "      self._shutdown_workers()\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "     if w.is_alive(): \n",
      "^ ^ ^ ^ ^ ^^ ^Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^\n",
      "    ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()^    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^      ^if w.is_alive():^ \n",
      "\n",
      "    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "          assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "       ^ ^^^^  ^^ ^ ^^^^ ^ ^^ ^^ ^^ ^^^^^^^^^^^Exception ignored in: ^^\n",
      "^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "^^^    Traceback (most recent call last):\n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^\n",
      "^      ^^^self._shutdown_workers()^ \n",
      "^ ^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^ ^^    ^ ^^if w.is_alive():^ ^ \n",
      "^^^  ^^ ^ ^^^ ^^^ ^^^ ^\n",
      " ^^^AssertionError^ ^: ^^^can only test a child process^^^^\n",
      "^^^^\n",
      "^^Exception ignored in: AssertionError^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^: ^^\n",
      "^can only test a child process\n",
      "^Traceback (most recent call last):\n",
      "^^^^Exception ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "    ^Traceback (most recent call last):\n",
      "^self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^\n",
      "        ^if w.is_alive():  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()\n",
      " \n",
      "^       File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process'    ^\n",
      " if w.is_alive():^  ^\n",
      "    ^   ^ ^ ^ ^ ^  \n",
      "^  AssertionError^ :  ^^can only test a child process ^^ \n",
      "^^ ^Exception ignored in: ^^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^\n",
      "^      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^self._shutdown_workers()    ^\n",
      "^^\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^\n",
      "^    ^if w.is_alive():   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^\n",
      "      ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^  \n",
      "^ ^    ^    ^   ^ ^    ^ ^ ^ ^ ^^^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^AssertionError^^^: ^^^can only test a child process\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  ^^\n",
      " ^^Traceback (most recent call last):\n",
      " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^^^     self._shutdown_workers()^^ \n",
      "^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^ ^^     ^ ^if w.is_alive():^^\n",
      "^^^^^^\n",
      " ^^ ^^AssertionError ^^:  ^ can only test a child process^^\n",
      "^ ^ \n",
      "^^AssertionError^^: ^^can only test a child process^^\n",
      "^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^^\n",
      "^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^Traceback (most recent call last):\n",
      "^      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^    ^\n",
      "self._shutdown_workers()^\n",
      "Exception ignored in:    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>     \n",
      "^ Traceback (most recent call last):\n",
      "^if w.is_alive(): ^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^    self._shutdown_workers()\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "      \n",
      "  if w.is_alive(): AssertionError  : \n",
      "    can only test a child process^  \n",
      "  ^ ^^ ^^^^ ^^^^ ^^^^^^^^^^^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^\n",
      "    ^^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^    ^^ ^self._shutdown_workers()^ ^^\n",
      "\n",
      "^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^^         assert self._parent_pid == os.getpid(), 'can only test a child process'^ if w.is_alive():^\n",
      "  \n",
      "  ^   ^   ^   ^  ^^ ^ ^ ^ ^ \n",
      "  ^AssertionError ^: ^^^^can only test a child process^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: \n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^\n",
      "^^    Traceback (most recent call last):\n",
      "^^assert self._parent_pid == os.getpid(), 'can only test a child process'^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "    ^^^self._shutdown_workers() ^^\n",
      "^ ^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^^     if w.is_alive(): ^^\n",
      "^ ^ ^^ ^  ^^ ^^   \n",
      "^ ^AssertionError^^:  can only test a child process ^\n",
      "\n",
      "^ AssertionError^^: ^^^can only test a child process^^\n",
      "^^^^^^^^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^  ^ ^ ^ ^ ^ ^  ^ ^^^^^^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ad8fc4116e475790de5aea23513d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 3/5] Val  :   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ New best model saved (val_loss=0.3353)\n",
      "Epoch 3/5 Train: loss=0.3691, acc=87.85% | Val: loss=0.3353, acc=88.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16400b7d5cb40e586e2bae8c838f554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 4/5] Train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "     if w.is_alive():  \n",
      "        Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>   \n",
      "^Traceback (most recent call last):\n",
      " ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^ ^^    self._shutdown_workers()^^^^\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^^    ^^if w.is_alive():\n",
      "^^^^ ^^  \n",
      "^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^     ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^^ ^^ ^ ^^ ^^Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^ ^^\n",
      "^ ^ Traceback (most recent call last):\n",
      "^^ ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^^    ^^ self._shutdown_workers()^^\n",
      "\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'    ^^if w.is_alive():\n",
      "\n",
      "^\n",
      "AssertionError^  ^:    can only test a child process^   \n",
      "^  ^  ^  ^ ^ ^^^ ^ ^^^^^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^\n",
      "^^Traceback (most recent call last):\n",
      "^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^    ^^self._shutdown_workers()^^^\n",
      "^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "if w.is_alive():^^ ^^\n",
      " ^^  \n",
      "^ AssertionError ^ :   ^ can only test a child process^\n",
      "  ^  ^   Exception ignored in: ^^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^^^^Traceback (most recent call last):\n",
      "^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^    ^^self._shutdown_workers()^^^^\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^\n",
      "^    if w.is_alive():^^AssertionError\n",
      "^^:  ^\n",
      "can only test a child process   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ \n",
      "    ^ assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "Exception ignored in: ^  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      " Traceback (most recent call last):\n",
      " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^ ^^^     self._shutdown_workers() ^^^ \n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^  ^    ^if w.is_alive(): ^^\n",
      " ^^  ^ ^^^ ^^^ \n",
      "^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^    ^ ^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
      "\n",
      " ^AssertionError^:  ^^ ^^can only test a child process ^ \n",
      "^^ ^^ ^Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^\n",
      " ^Traceback (most recent call last):\n",
      "^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^ ^^    ^^^^^self._shutdown_workers()^^\n",
      "^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^    ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^if w.is_alive():^\n",
      "\n",
      "^^ ^^  ^^  ^^  ^^ ^ ^  ^ ^ ^^ \n",
      "^ ^ AssertionError^^^ :  ^can only test a child process^^\n",
      "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^^^\n",
      "^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^    ^^self._shutdown_workers()^\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^    ^^^if w.is_alive():\n",
      "^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "       ^  ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^^^^\n",
      "^\n",
      "^^AssertionError ^^: ^^^can only test a child process ^\n",
      "^ ^^  ^ ^^^ ^^ ^ ^^ ^\n",
      "^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^Exception ignored in:     ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^^\n",
      "Traceback (most recent call last):\n",
      "^ \n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "AssertionError ^    ^ : self._shutdown_workers()^can only test a child process \n",
      "\n",
      "^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^      ^if w.is_alive():^ \n",
      "^  ^  Exception ignored in: ^  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^ ^ ^^\n",
      " ^ ^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^    ^^^^self._shutdown_workers()^^^^^\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^^^^    ^^^if w.is_alive():^^^\n",
      "\n",
      "^^ ^^AssertionError:  ^^can only test a child process \n",
      "^\n",
      "^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^     ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^ \n",
      "^^ ^ ^ ^^^Exception ignored in: ^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^ ^^\n",
      " Traceback (most recent call last):\n",
      "^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^ ^^     ^^self._shutdown_workers() ^\n",
      "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    ^^    if w.is_alive():^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "\n",
      "\n",
      "^ AssertionError  ^:  ^ ^can only test a child process  ^ \n",
      " ^ ^  ^  ^ ^^ ^^ ^^ ^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^^\n",
      "^^^^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^    ^^^self._shutdown_workers()^^^\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^if w.is_alive():^    ^\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^^   ^ ^^ \n",
      "^AssertionError ^  :  can only test a child process^  \n",
      "^  ^^ Exception ignored in: ^^ ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^ ^\n",
      " ^^ Traceback (most recent call last):\n",
      "^^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^^^    ^^^^^self._shutdown_workers()^\n",
      "^^^\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^AssertionError\n",
      "    ^: if w.is_alive():^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "can only test a child process^     ^\n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
      "Exception ignored in:   ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  ^   \n",
      "^ Traceback (most recent call last):\n",
      " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^ ^^     ^self._shutdown_workers() ^^ \n",
      "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^ ^ ^    ^if w.is_alive():^^^^^^\n",
      "^^ ^^^^ ^^ ^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^\n",
      "    ^ AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'^: ^ \n",
      "^can only test a child process  ^\n",
      "^ ^ ^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> ^\n",
      "^ ^Traceback (most recent call last):\n",
      " ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^     ^^ ^^ self._shutdown_workers()^ ^\n",
      " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^^^^    ^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():^^\n",
      "^     ^^ ^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
      "^ \n",
      "  ^AssertionError ^ :   ^can only test a child process ^^\n",
      "^^^ ^ ^^ ^^ ^^ ^^^^ ^^ ^^^^^^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^ ^^ ^^ ^ ^^ ^^^ ^ ^^ \n",
      " ^AssertionError ^:  ^^can only test a child process^^\n",
      "^^^^^^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "^^Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "^AssertionError    : self._shutdown_workers()^can only test a child process\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^    ^if w.is_alive():^^\n",
      "^ ^^ ^^ ^Exception ignored in:  ^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> \n",
      "^ ^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^\n",
      "^AssertionError    : ^self._shutdown_workers()^\n",
      "can only test a child process  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^    ^if w.is_alive():^^\n",
      " ^ ^ ^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      " Traceback (most recent call last):\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "       ^^self._shutdown_workers() ^ \n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^      ^if w.is_alive(): ^\n",
      "  ^ ^  ^ ^ ^ ^^ \n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^    ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^\n",
      "^^ ^^ ^^^ ^^ ^ ^ ^ ^ ^^^ ^^ \n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^ ^^ ^^ ^ ^^ ^ ^^ ^^ ^^ ^\n",
      "^ AssertionError^ : ^^^^can only test a child process^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^: ^can only test a child process\n",
      "^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1881bbf265c4f7c9832e6775f4876c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 4/5] Val  :   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 Train: loss=0.2760, acc=90.76% | Val: loss=0.4031, acc=86.56%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8982ca64a84928aa317bcb7d695a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 5/5] Train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "      Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "^Traceback (most recent call last):\n",
      "Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    ^^    self._shutdown_workers()self._shutdown_workers()\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "    ^if w.is_alive():^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      " ^    ^ Exception ignored in:  if w.is_alive():\n",
      " \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  \n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "         File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'     \n",
      " self._shutdown_workers()  \n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "if w.is_alive(): ^    ^^\n",
      " ^^^  ^^^ ^^^ ^^ ^  ^ ^^  ^^^ ^^ ^  \n",
      "\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    ^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^^ ^   \n",
      "^^^  ^^  ^ ^^ ^ ^\n",
      " ^^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^    ^^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^   ^^^^  ^  ^ ^^ ^ ^^^^ ^ ^^ ^^^ ^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^AssertionError^^: ^^can only test a child process^\n",
      "^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "^^^Traceback (most recent call last):\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^^^    ^^^^self._shutdown_workers()^^^\n",
      "\n",
      "^^AssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^:     ^can only test a child process^^^if w.is_alive():^\n",
      "\n",
      "^^ Exception ignored in:  ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^ \n",
      "^^Traceback (most recent call last):\n",
      " ^^^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^ ^     \n",
      "self._shutdown_workers()AssertionError^\n",
      "\n",
      ": ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^can only test a child processAssertionError^: ^    ^can only test a child process\n",
      "^\n",
      "if w.is_alive():^^\n",
      "Exception ignored in: Exception ignored in: ^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      " ^Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " \n",
      "Traceback (most recent call last):\n",
      "\n",
      "       File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()     self._shutdown_workers()\n",
      "       File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^         if w.is_alive(): \n",
      "if w.is_alive():^\n",
      "   ^      ^     ^    ^  ^ ^^ ^^^^ ^^^^^^^^^^^^^\n",
      "^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^\n",
      "^^ ^^^^^ ^^^^ ^^^ ^^^\n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
      "^      assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "      ^     ^^  ^  ^^  ^^^ ^^   ^^^  ^^ ^ ^\n",
      "^^AssertionError^^^: ^^can only test a child process^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "^^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^    ^^^^self._shutdown_workers()^^\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^^^    ^^if w.is_alive():^^^\n",
      "^^ ^^^ ^^^ \n",
      "^^ AssertionError^^^ : ^^^ can only test a child process^ \n",
      "^^^^^^\n",
      "^\n",
      "AssertionError^^AssertionError^^: : can only test a child processcan only test a child process\n",
      "^\n",
      "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80><function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> self._shutdown_workers()\n",
      "\n",
      "\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " Traceback (most recent call last):\n",
      " Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "if w.is_alive():   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "             self._shutdown_workers() self._shutdown_workers() \n",
      "\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^         ^ if w.is_alive(): ^if w.is_alive():\n",
      "\n",
      "^^ ^ ^^^  ^  ^^  ^ ^ ^^^  ^ ^^ ^^^^^^^^^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^    ^^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^^^^ ^^^^ ^^^^ ^^^^\n",
      "^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^^^\n",
      "      ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^        assert self._parent_pid == os.getpid(), 'can only test a child process'  ^   \n",
      "^^ \n",
      " ^  ^ AssertionError  :   ^ can only test a child process \n",
      "^ ^^ ^ ^^^Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^ ^^\n",
      "^^Traceback (most recent call last):\n",
      " ^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^^^^    ^self._shutdown_workers()^^^\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^    ^^^^if w.is_alive():^^\n",
      "^^^ ^^ ^^^^ ^^ ^ ^^^ ^^ ^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError^^^\n",
      ": ^AssertionError^^: can only test a child processcan only test a child process\n",
      "^^\n",
      "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^Exception ignored in: \n",
      "^      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>self._shutdown_workers()^    \n",
      "^\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^          ^if w.is_alive():self._shutdown_workers()^\n",
      " \n",
      " ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  ^      ^ ^   if w.is_alive(): \n",
      "  AssertionError^\n",
      "  : ^ ^can only test a child process^ ^ \n",
      " ^ ^ ^^^^Exception ignored in: ^^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^^\n",
      "^^^Traceback (most recent call last):\n",
      "^^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^    ^^self._shutdown_workers()^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "        ^    assert self._parent_pid == os.getpid(), 'can only test a child process'^if w.is_alive():^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^\n",
      "\n",
      "       ^   ^      ^   ^    ^   ^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^AssertionError^^\n",
      ": ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^^can only test a child process^\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^^ ^^^^ ^^ ^  ^^ ^^ ^^^^^Exception ignored in:  ^ ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^ ^^^^^\n",
      "^^^^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^\n",
      "    AssertionError^^: self._shutdown_workers()^^\n",
      "can only test a child process^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "    ^\n",
      "AssertionError^if w.is_alive():^\n",
      " : ^can only test a child process \n",
      " ^  ^  ^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^Exception ignored in: ^\n",
      "^^Traceback (most recent call last):\n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^\n",
      "^Traceback (most recent call last):\n",
      "    ^^^self._shutdown_workers()\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "self._shutdown_workers()    ^^ \n",
      "if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^ ^\n",
      "^      ^  if w.is_alive():^ \n",
      " ^\n",
      "  AssertionError :    can only test a child process   \n",
      "  ^  ^  ^  ^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^\n",
      "^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'    ^^\n",
      "self._shutdown_workers()^\n",
      " ^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^     ^ ^^if w.is_alive():^\n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^    \n",
      " ^ assert self._parent_pid == os.getpid(), 'can only test a child process' ^  ^\n",
      "   ^  ^  ^^ ^^ ^ ^^ ^^^ ^^^ ^^^ ^^^ ^^^^^^^ ^^\n",
      "^AssertionError^^:  can only test a child process^^\n",
      " ^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^Traceback (most recent call last):\n",
      "^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^self._shutdown_workers()    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^^     ^^ if w.is_alive():^^ \n",
      " ^ ^  ^ ^ ^   ^^^  ^ ^ ^ ^\n",
      "^^AssertionError^^: ^^can only test a child process^^^\n",
      "^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^^^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^    self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
      "\n",
      "\n",
      "^ ^AssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^     : can only test a child processif w.is_alive():^\n",
      " \n",
      "^   ^ ^    Exception ignored in:  ^   ^  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "^Traceback (most recent call last):\n",
      "^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^    ^^^self._shutdown_workers()^\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^    \n",
      "^AssertionErrorif w.is_alive():^: ^^^can only test a child process\n",
      "^\n",
      "^^^^Exception ignored in: ^ \n",
      "^^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^\n",
      " ^    ^Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^assert self._parent_pid == os.getpid(), 'can only test a child process'     ^\n",
      "self._shutdown_workers() ^ \n",
      " ^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^  ^      ^^ ^^if w.is_alive():^^ \n",
      "^  ^ ^  ^  ^^^^ ^^^^^ ^ ^^^\n",
      "^\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError^    : assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process^\n",
      "^\n",
      " ^^^^^^ ^^ ^^ ^^^^^ ^ ^ ^ ^^ ^^\n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " Exception ignored in: ^    ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^^\n",
      " Traceback (most recent call last):\n",
      "^  ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^     ^ self._shutdown_workers()^\n",
      " ^ ^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    ^^ if w.is_alive(): ^^^\n",
      "^^^^ ^^ \n",
      "^^ ^AssertionError^^ : ^ ^can only test a child process^\n",
      "^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^\n",
      "^\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    ^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "self._shutdown_workers()^ ^ \n",
      " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^ ^^^     \n",
      " AssertionError ^: if w.is_alive(): can only test a child process^\n",
      "\n",
      " \n",
      "  ^AssertionError^ : can only test a child process ^ ^\n",
      "Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> ^\n",
      " ^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    ^^self._shutdown_workers()^\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>    if w.is_alive():^\n",
      "\n",
      " ^Traceback (most recent call last):\n",
      "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^    self._shutdown_workers()^\n",
      " ^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^    ^if w.is_alive():^^\n",
      "^^  ^ \n",
      "  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^ ^^^^ ^\n",
      "^^ ^^^ ^^^^^ ^^^ ^^ ^^^\n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^    \n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process' AssertionError ^: ^ ^\n",
      "can only test a child process  ^\n",
      " \n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^     ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^ ^\n",
      "   ^^  ^ ^  ^^^^ ^ ^^^^ ^^ ^^^^^ ^ ^^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^AssertionError^: ^can only test a child process^^\n",
      "^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError: ^^can only test a child process\n",
      "^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "     if w.is_alive(): \n",
      "              ^  ^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^    ^^self._shutdown_workers()^^\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "    ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():^    \n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      " ^  ^  ^    ^   ^ ^ ^^ ^^ ^ ^^^^^^^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^^Traceback (most recent call last):\n",
      "\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^        ^self._shutdown_workers()^\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    ^AssertionErrorif w.is_alive(): ^ : ^\n",
      "can only test a child process ^ \n",
      "^ ^ ^  Exception ignored in: ^  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> \n",
      "^ ^ Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^      self._shutdown_workers()^ \n",
      "^\n",
      "^AssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " :     can only test a child process^^\n",
      "if w.is_alive():^^\n",
      "^ ^^Exception ignored in: ^ ^^^^ ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "^ ^Traceback (most recent call last):\n",
      " ^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "     ^^^^self._shutdown_workers()^^^\n",
      "\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^^    ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^    ^\n",
      "^^^ ^if w.is_alive(): \n",
      "^ ^^  ^    ^^  \n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^      ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^ \n",
      "^^  ^  ^^^ ^^\n",
      "^^AssertionError ^: ^^ can only test a child process^\n",
      "^ ^Exception ignored in:  ^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      " ^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^    ^^ self._shutdown_workers()\n",
      "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^    if w.is_alive():^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^      ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^ \n",
      "^^ ^ ^ ^ ^^ ^^ ^^^  ^^ ^^ ^^^ ^^^^^ ^^ ^^^ ^^^^^ ^^^\n",
      "^^^^AssertionError^^^: ^^can only test a child process^\n",
      "^^\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^^^^Traceback (most recent call last):\n",
      "^^\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " ^\n",
      "     ^AssertionError^: self._shutdown_workers() ^ can only test a child process ^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " \n",
      " ^      ^ if w.is_alive(): ^^\n",
      "^^^^ ^^^^^ ^^^Exception ignored in: ^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "^ ^^Traceback (most recent call last):\n",
      " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^    ^^ ^self._shutdown_workers()^^\n",
      "^^ ^^^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^^    \n",
      "^if w.is_alive():^^^\n",
      "^ ^ AssertionError^^: can only test a child process^^ ^\n",
      "^^^^^^^ \n",
      " AssertionError\n",
      " :   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "can only test a child process    \n",
      "Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "     \n",
      "^self._shutdown_workers() ^Exception ignored in:  ^\n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^    Traceback (most recent call last):\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "if w.is_alive(): ^     \n",
      "^ ^ self._shutdown_workers()  ^\n",
      "     File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^       ^^ ^if w.is_alive():^\n",
      " ^\n",
      "^  ^^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^ ^^^ ^ ^^    ^^^^^^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^^^^\n",
      "^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "\n",
      "    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'^ \n",
      "     ^       ^^   ^     ^ ^ ^ ^^ ^^  ^^^^ ^^ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^AssertionError^^^^^^: ^^^^can only test a child process^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^\n",
      "^^^AssertionError^^Exception ignored in: : ^^can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "^\n",
      "Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    ^^self._shutdown_workers()Exception ignored in: ^\n",
      "^\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>AssertionError\n",
      "    : ^if w.is_alive():Traceback (most recent call last):\n",
      "can only test a child process^\n",
      "\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " \n",
      "Exception ignored in:  AssertionError    <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> : self._shutdown_workers() can only test a child process\n",
      " \n",
      "\n",
      "Traceback (most recent call last):\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "Exception ignored in: ^^        if w.is_alive():self._shutdown_workers()^\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> ^ \n",
      "^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^Traceback (most recent call last):\n",
      "     ^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^      ^if w.is_alive():self._shutdown_workers()^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^ \n",
      "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():  \n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^  ^ ^ ^^^\n",
      "  ^\n",
      "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^      ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^  ^\n",
      "^ ^^ ^ ^^ ^^ ^  ^  ^^  ^ \n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^ ^     ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ ^ ^  ^^ ^^ ^^ ^^^ ^^\n",
      "^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^^     ^  ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^^^ ^^ ^^^^ ^^ ^^^^ ^^^^ ^^ ^^ ^^ ^^^^^^ ^^^ ^^^^^^^^^^^^^^^^^^^\n",
      "^^^AssertionError^: ^^^can only test a child process^^^^\n",
      "^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^^\n",
      "^^Traceback (most recent call last):\n",
      "^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    ^^^^^self._shutdown_workers()^^^^\n",
      "\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^AssertionError^^^: ^^    if w.is_alive():^can only test a child process^\n",
      "\n",
      "\n",
      "^ AssertionError:  ^ can only test a child process^ \n",
      "^ ^ ^ ^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "\n",
      "^Traceback (most recent call last):\n",
      "AssertionError^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^:     Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>can only test a child process^^self._shutdown_workers()\n",
      "\n",
      "^\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^    ^    if w.is_alive():^self._shutdown_workers()\n",
      "\n",
      "\n",
      "Exception ignored in:   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> \n",
      "         Traceback (most recent call last):\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "\n",
      "       self._shutdown_workers()   \n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "       ^if w.is_alive(): ^ ^  ^\n",
      "^ ^  ^^ ^     ^^ ^  ^^\n",
      " ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^     ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^\n",
      "^ ^^ ^^^^ ^^^^^ ^\n",
      "^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^    ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^  \n",
      "^^^^\n",
      " ^    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "     ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^ ^\n",
      "  ^  ^^ ^  ^   ^^ ^^  ^^ ^^ ^ ^^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^AssertionError^^^^^^^^: ^^^can only test a child process^^^^^^\n",
      "^^^^^^^^^^^^^^^^^\n",
      "^^^^AssertionError^: can only test a child process^\n",
      "^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "^^Traceback (most recent call last):\n",
      "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "Exception ignored in: ^^^    \n",
      "self._shutdown_workers()^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>AssertionError\n",
      "\n",
      ": AssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "can only test a child process: \n",
      "Traceback (most recent call last):\n",
      "can only test a child process    \n",
      "Exception ignored in: if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>Exception ignored in: \n",
      " Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "     \n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      " \n",
      "self._shutdown_workers()    \n",
      " self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "     \n",
      "    if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "     if w.is_alive():\n",
      " ^if w.is_alive(): ^\n",
      " ^\n",
      "  ^  ^   ^   ^ ^ ^^  ^^ ^ ^^^^ ^^^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^    ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
      "^ ^^^^ ^ ^^^^ ^^^ ^ ^\n",
      " ^^ ^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "          assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "\n",
      "^ ^ \n",
      " ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^     ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^\n",
      " ^   ^^ ^  ^    ^   ^   ^ ^ ^^ ^^ ^^^^^^ ^^ ^^^^^^ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError^^^^: ^^can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "AssertionError^AssertionError^: ^: can only test a child process\n",
      "^can only test a child process^\n",
      "^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86d08488f2b42c987aacba59e5c649d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 5/5] Val  :   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "    Exception ignored in: Exception ignored in: self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80><function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "    \n",
      "if w.is_alive():\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "    Traceback (most recent call last):\n",
      " Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "           self._shutdown_workers() self._shutdown_workers()\n",
      "  \n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "      if w.is_alive(): \n",
      "      if w.is_alive():   \n",
      "^   ^ ^ ^^  ^ ^^ ^ ^  ^^^^^ ^^^^^^^^^^^^^^^^^^\n",
      "^\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "^^ \n",
      "^^  ^ \n",
      "^  \n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "           assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'   \n",
      " \n",
      "               ^^   ^ ^ ^ ^ ^  ^^^  ^  ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^AssertionError^^^^: ^^^\n",
      "can only test a child process^\n",
      "AssertionError^^: ^^can only test a child process^^Exception ignored in: ^\n",
      "^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^Exception ignored in: ^\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "AssertionErrorTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "AssertionError:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    : can only test a child processcan only test a child process\n",
      "self._shutdown_workers()    \n",
      "\n",
      "self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    \n",
      "Exception ignored in: if w.is_alive():    Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "if w.is_alive():\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      " Traceback (most recent call last):\n",
      "      self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  \n",
      "        File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " self._shutdown_workers()      \n",
      "  if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " \n",
      "^      ^^if w.is_alive(): ^ \n",
      "^^^ ^ ^ ^  ^ ^^^^^ ^^^^ ^^^ ^^^^ ^^\n",
      " \n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^        ^^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^\n",
      "^^  ^ ^ ^  ^\n",
      " ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  ^  ^     assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
      " ^   \n",
      "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^      ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^ ^ \n",
      "  ^ ^ ^  ^^^^  ^^  ^^^^ ^^^^ ^ ^^^^ ^^ ^^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^\n",
      "^AssertionError: ^^AssertionErrorcan only test a child process^^: ^\n",
      "^can only test a child process\n",
      "^AssertionError\n",
      "^: ^^can only test a child process^\n",
      "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>AssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      ": Traceback (most recent call last):\n",
      "can only test a child process    Exception ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "        self._shutdown_workers()if w.is_alive():if w.is_alive():\n",
      "\n",
      "\n",
      "Exception ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>       \n",
      "if w.is_alive():  \n",
      " Traceback (most recent call last):\n",
      "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "           ^ self._shutdown_workers()\n",
      "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^^^     ^^if w.is_alive():^^ \n",
      " ^^^^ ^^^ ^^^^^  ^^^ ^^ ^^^ \n",
      "^\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^        ^^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
      "\n",
      "\n",
      " ^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  ^       assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "^   ^    ^   ^   ^    \n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  ^^    ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^ \n",
      "^^  ^^^  ^^ ^^^^^^^^ ^^^^ ^^^^ ^^^ ^^ ^^^^ ^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "^^AssertionErrorAssertionError^: ^: ^^can only test a child process^can only test a child process^\n",
      "\n",
      "^^^Exception ignored in: ^\n",
      "Exception ignored in: ^AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80><function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>: ^\n",
      "can only test a child process\n",
      "^Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^        ^self._shutdown_workers()Exception ignored in: self._shutdown_workers()\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^    \n",
      "    if w.is_alive():Traceback (most recent call last):\n",
      "if w.is_alive():^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "^ \n",
      "      AssertionErrorself._shutdown_workers()  :  \n",
      " can only test a child process  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "          Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>if w.is_alive():^^\n",
      "\n",
      "^^ Traceback (most recent call last):\n",
      " ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^ ^    ^ self._shutdown_workers()^^ \n",
      "^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^ ^    ^^^^^if w.is_alive():^^^^\n",
      "^^^^ ^ ^\n",
      "\n",
      "^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    ^     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process'  ^\n",
      " ^     ^^ ^ \n",
      "^ ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^      ^ assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "^   ^  ^   ^^  ^^ ^^ \n",
      "^    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^     ^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
      "^^ ^  ^  ^^ ^^^ ^^^ ^^^ ^^^^ ^^^ ^^^^^ ^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^^: ^can only test a child process^^\n",
      "^\n",
      "^AssertionError^: ^^^^^can only test a child process^^\n",
      "^^^^\n",
      "^AssertionErrorException ignored in: : ^can only test a child process^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "\n",
      "Exception ignored in: ^^Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "Traceback (most recent call last):\n",
      "AssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      ":         can only test a child processself._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "        Exception ignored in: if w.is_alive():if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "\n",
      " \n",
      "  Traceback (most recent call last):\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "        Exception ignored in:  self._shutdown_workers()  <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "  \n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^Traceback (most recent call last):\n",
      "    ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "if w.is_alive():^^^^\n",
      "^     ^ self._shutdown_workers()^^ ^\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^^^     ^ ^if w.is_alive():^^\n",
      " ^^^ \n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^^\n",
      "     ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process' ^     ^\n",
      "^ assert self._parent_pid == os.getpid(), 'can only test a child process'  ^\n",
      " ^  ^^  ^  ^^^  \n",
      "  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  ^^      ^  assert self._parent_pid == os.getpid(), 'can only test a child process'^  \n",
      "^ ^ ^ ^^  ^^ ^^^ ^\n",
      "^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^     ^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^ ^\n",
      "^  ^ ^ ^^ ^^^^ ^^ ^^^ ^^^ ^^ ^^ ^^^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError^^^^^^: \n",
      "^^can only test a child processAssertionError^^\n",
      "^: ^^can only test a child process^Exception ignored in: ^^\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^\n",
      "^Exception ignored in: ^^Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "^Traceback (most recent call last):\n",
      "^    ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^self._shutdown_workers()\n",
      "^\n",
      "    AssertionError^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "self._shutdown_workers(): ^\n",
      "can only test a child process    \n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "AssertionError\n",
      "     : if w.is_alive(): Exception ignored in: \n",
      "can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "  \n",
      " Traceback (most recent call last):\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  Exception ignored in:      <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>  self._shutdown_workers()^\n",
      " \n",
      "Traceback (most recent call last):\n",
      "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    ^^    if w.is_alive():^^\n",
      "^^self._shutdown_workers() ^\n",
      "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^ ^    ^ ^^if w.is_alive():^^^ \n",
      " ^  ^^^^\n",
      " \n",
      "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "        ^ assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^ \n",
      "\n",
      "  ^ ^    ^^   ^^ ^ ^ ^ ^^^  ^^  ^\n",
      " ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  ^     ^ assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ ^ ^^ ^^^ ^\n",
      " ^^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^ ^     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      " ^^  ^^  ^ ^ ^ ^^^^ ^ ^^^^ ^^ ^^^^^^^^^ ^^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^AssertionError^\n",
      "^: ^^AssertionError^can only test a child process: ^^\n",
      "can only test a child process^^^^\n",
      "^^^\n",
      "^^AssertionError^: ^can only test a child process^Exception ignored in: \n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>Exception ignored in: \n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>Traceback (most recent call last):\n",
      "\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "        AssertionError: self._shutdown_workers()self._shutdown_workers()\n",
      "Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "    if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "if w.is_alive():\n",
      "    \n",
      "   self._shutdown_workers()  \n",
      "    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "       Exception ignored in:  if w.is_alive(): <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      " ^\n",
      "  ^Traceback (most recent call last):\n",
      "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^      ^^self._shutdown_workers() ^\n",
      "^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "^^^     ^^^^if w.is_alive():^^^^^\n",
      "^^^ ^\n",
      "^ ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " \n",
      "^       File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^    assert self._parent_pid == os.getpid(), 'can only test a child process'^ \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  ^\n",
      "^^  ^^  ^ ^\n",
      "    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^      ^ assert self._parent_pid == os.getpid(), 'can only test a child process' ^  \n",
      "^   ^   ^     ^ ^ ^^^^ ^ ^^^ ^\n",
      "^^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^    ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
      "^^^^ ^^^ ^^^ ^^^ ^^ ^^^ ^^^^ ^^ ^^^^^^ ^^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "^^AssertionError^AssertionError: ^^can only test a child process: ^^can only test a child process\n",
      "^\n",
      "\n",
      "^AssertionErrorException ignored in: ^: ^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^can only test a child process\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "\n",
      "^    Exception ignored in: Traceback (most recent call last):\n",
      "^self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80>^\n",
      "    ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^self._shutdown_workers()    \n",
      "^Traceback (most recent call last):\n",
      "if w.is_alive():^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "\n",
      "^          ^  self._shutdown_workers()\n",
      "if w.is_alive(): AssertionError\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      ":   can only test a child process      \n",
      " if w.is_alive():^ Exception ignored in: \n",
      "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e72be619f80> ^ \n",
      " ^Traceback (most recent call last):\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "^^ ^^     ^self._shutdown_workers() ^^\n",
      "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      " ^^^^    ^^^if w.is_alive():^^\n",
      "^^\n",
      " ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^^     ^^ assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^^ \n",
      "^ \n",
      "  ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "     ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ \n",
      "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^      ^ assert self._parent_pid == os.getpid(), 'can only test a child process'  ^\n",
      "  ^   ^ ^ ^  ^^ ^^  \n",
      "^   ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "     ^^^ ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
      "^^   ^^ ^^^^  ^^^^^^ ^^ ^^^ ^^^ ^^^ ^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^\n",
      "^^AssertionErrorAssertionError^: ^^can only test a child process: ^^\n",
      "^can only test a child process^\n",
      "\n",
      "^AssertionError^: ^^^can only test a child process^\n",
      "\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ New best model saved (val_loss=0.3105)\n",
      "Epoch 5/5 Train: loss=0.2211, acc=92.51% | Val: loss=0.3105, acc=89.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1434820020.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# ---- setup outside ----\n",
    "model     = FontClassifier(pretrained_scae, num_classes=200).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "\n",
    "# ---- call train() ----\n",
    "best_model, history = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler=scheduler,\n",
    "    device='cuda',\n",
    "    num_epochs=5,\n",
    "    early_stopping_patience=7,\n",
    "    checkpoint_path=\"/kaggle/working/classifier_checkpoints/best_font_model.pt\",\n",
    "    use_amp=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4fa1f",
   "metadata": {
    "papermill": {
     "duration": 0.405353,
     "end_time": "2025-05-20T18:27:14.747053",
     "exception": false,
     "start_time": "2025-05-20T18:27:14.341700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## HENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc04bf2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:27:15.627696Z",
     "iopub.status.busy": "2025-05-20T18:27:15.626608Z",
     "iopub.status.idle": "2025-05-20T18:27:15.631381Z",
     "shell.execute_reply": "2025-05-20T18:27:15.630756Z"
    },
    "papermill": {
     "duration": 0.48246,
     "end_time": "2025-05-20T18:27:15.632545",
     "exception": false,
     "start_time": "2025-05-20T18:27:15.150085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top1_error, top5_error = evaluate_model_optimized(\n",
    "#     trained_model, \n",
    "#     test_font_loader, \n",
    "#     device=device,\n",
    "#     use_amp=True\n",
    "# )\n",
    "\n",
    "# print(f\"Final Results:\")\n",
    "# print(f\"Top-1 Error: {top1_error:.2f}%\")\n",
    "# print(f\"Top-5 Error: {top5_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d938ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:27:16.481348Z",
     "iopub.status.busy": "2025-05-20T18:27:16.481066Z",
     "iopub.status.idle": "2025-05-20T18:27:16.486083Z",
     "shell.execute_reply": "2025-05-20T18:27:16.485415Z"
    },
    "papermill": {
     "duration": 0.430557,
     "end_time": "2025-05-20T18:27:16.487121",
     "exception": false,
     "start_time": "2025-05-20T18:27:16.056564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # HEBlock + HENet\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.models as models\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# class HEBlock(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Optimized HE (Hide and Enhance) Block implementation.\n",
    "#     Vectorized implementation to eliminate slow Python loops.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, beta=0.5):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             beta: weight of mask (default: 0.5 as recommended in the paper)\n",
    "#         \"\"\"\n",
    "#         super(HEBlock, self).__init__()\n",
    "#         self.beta = beta\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             x: input feature map of shape (batch_size, C, H, W)\n",
    "#         Returns:\n",
    "#             Modified feature map with suppressed maximum activations\n",
    "#         \"\"\"\n",
    "#         if not self.training:  # Only apply during training\n",
    "#             return x\n",
    "        \n",
    "#         # Get shape information\n",
    "#         batch_size, channels, h, w = x.size()\n",
    "        \n",
    "#         # Find maximum values for each channel in each sample in batch\n",
    "#         # Shape: [batch_size, channels, 1, 1]\n",
    "#         max_vals = x.view(batch_size, channels, -1).max(dim=2)[0].view(batch_size, channels, 1, 1)\n",
    "        \n",
    "#         # Create masks where the value equals the max value\n",
    "#         # Broadcasting handles the comparison efficiently\n",
    "#         mask = (x == max_vals).float()\n",
    "        \n",
    "#         # Apply the beta factor to maximum values using the mask\n",
    "#         # This is a vectorized operation that replaces the nested loops\n",
    "#         output = torch.where(mask == 1, self.beta * x, x)\n",
    "        \n",
    "#         return output\n",
    "\n",
    "\n",
    "# class HENet(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Optimized HENet implementation for font recognition.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_classes=2383, beta=0.5, use_amp=True):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             num_classes: Number of font classes (default: 2383)\n",
    "#             beta: Weight for the HE Block mask (default: 0.5)\n",
    "#             use_amp: Whether to use Automatic Mixed Precision (default: True)\n",
    "#         \"\"\"\n",
    "#         super(HENet, self).__init__()\n",
    "        \n",
    "#         # Track whether to use mixed precision\n",
    "#         self.use_amp = use_amp\n",
    "        \n",
    "#         # Load pretrained ResNet18 - efficient backbone architecture\n",
    "#         self.resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "#         # Modify the first convolutional layer to accept grayscale input\n",
    "#         self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "#         # Remove the final fully connected layer to use as feature extractor\n",
    "#         self.features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "        \n",
    "#         # 1x1 convolution to match the number of classes (more efficient than FC for large number of classes)\n",
    "#         self.conv_final = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        \n",
    "#         # Optimized HE Block\n",
    "#         self.he_block = HEBlock(beta=beta)\n",
    "        \n",
    "#         # Global average pooling for efficient dimensionality reduction\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # Use AMP if specified (faster computation with minimal accuracy loss)\n",
    "#         with torch.cuda.amp.autocast() if self.use_amp and torch.cuda.is_available() else torch.no_grad():\n",
    "#             # Feature extraction using ResNet backbone\n",
    "#             x = self.features(x)\n",
    "            \n",
    "#             # 1x1 convolution to get class-specific activation maps\n",
    "#             x = self.conv_final(x)\n",
    "            \n",
    "#             # Apply HE Block during training (now optimized)\n",
    "#             x = self.he_block(x)\n",
    "            \n",
    "#             # Global average pooling and flatten\n",
    "#             x = self.avgpool(x)\n",
    "#             x = torch.flatten(x, 1)\n",
    "            \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "173f9d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:27:17.304602Z",
     "iopub.status.busy": "2025-05-20T18:27:17.304292Z",
     "iopub.status.idle": "2025-05-20T18:27:17.311808Z",
     "shell.execute_reply": "2025-05-20T18:27:17.311069Z"
    },
    "papermill": {
     "duration": 0.38549,
     "end_time": "2025-05-20T18:27:17.312945",
     "exception": false,
     "start_time": "2025-05-20T18:27:16.927455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # optimized_train_eval.py\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "# from tqdm.auto import tqdm\n",
    "# import time\n",
    "# import os\n",
    "# from datetime import timedelta\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# def train_model_optimized(model, train_loader, val_loader, num_epochs=100, \n",
    "#                           device='cuda', use_amp=True, use_compile=False,\n",
    "#                           gradient_accumulation_steps=4, save_dir='checkpoints'):\n",
    "#     \"\"\"\n",
    "#     Optimized training function with support for:\n",
    "#     - Automatic Mixed Precision (AMP)\n",
    "#     - Gradient accumulation\n",
    "#     - Detailed monitoring\n",
    "#     - Model checkpointing\n",
    "#     - Compatibility with older GPUs\n",
    "#     \"\"\"\n",
    "#     # Create directory for checkpoints\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "#     # Check GPU compatibility for torch.compile\n",
    "#     if use_compile and hasattr(torch, 'compile'):\n",
    "#         # Only enable on supported hardware (CUDA capability >= 7.0)\n",
    "#         if torch.cuda.is_available():\n",
    "#             device_cap = torch.cuda.get_device_capability(torch.cuda.current_device())\n",
    "#             if device_cap[0] < 7:\n",
    "#                 use_compile = False\n",
    "#                 print(f\"GPU CUDA capability {device_cap[0]}.{device_cap[1]} is too old for torch.compile(). Disabling.\")\n",
    "#             else:\n",
    "#                 model = torch.compile(model)\n",
    "#                 print(\"Using torch.compile() to optimize model execution\")\n",
    "    \n",
    "#     # Loss function, optimizer and scheduler\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(\n",
    "#         model.parameters(),\n",
    "#         lr=0.01,             # base learning rate from the paper\n",
    "#         momentum=0.9,        # typical momentum\n",
    "#         weight_decay=5e-4    # small L2 regularization\n",
    "#     )\n",
    "#     scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "#         optimizer,\n",
    "#         max_lr=0.1,          \n",
    "#         total_steps=math.ceil(len(train_loader) / gradient_accumulation_steps) * num_epochs,  # Use math.ceil instead of //\n",
    "#         pct_start=0.2,       \n",
    "#         anneal_strategy='cos',\n",
    "#         div_factor=10,       \n",
    "#         final_div_factor=1e4 \n",
    "#     )\n",
    "    \n",
    "#     # Initialize AMP scaler if using AMP\n",
    "#     scaler = GradScaler() if use_amp and device != 'cpu' else None\n",
    "    \n",
    "#     # Move model to device\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     # For tracking best model\n",
    "#     best_val_error = float('inf')\n",
    "#     best_model_state = None\n",
    "    \n",
    "#     # Training loop\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "#         epoch_start = time.time()\n",
    "        \n",
    "#         # === TRAINING PHASE ===\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "        \n",
    "#         # Progress bar for training\n",
    "#         train_pbar = tqdm(\n",
    "#             total=len(train_loader),\n",
    "#             desc=f\"Training\",\n",
    "#             unit=\"batch\",\n",
    "#             leave=True,\n",
    "#             bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\"\n",
    "#         )\n",
    "        \n",
    "#         # Track batch-level metrics\n",
    "#         batch_times = []\n",
    "        \n",
    "#         # Zero gradients at the start of epoch\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "#             batch_start = time.time()\n",
    "            \n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "#             # Forward pass with AMP if enabled\n",
    "#             step_count = 0\n",
    "#             total_steps = math.ceil(len(train_loader) / gradient_accumulation_steps) * num_epochs\n",
    "#             if use_amp and device != 'cpu':\n",
    "#                 with autocast():\n",
    "#                     outputs = model(inputs)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                     # Scale loss by gradient accumulation steps\n",
    "#                     loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "#                 # Backward pass with AMP\n",
    "#                 scaler.scale(loss).backward()\n",
    "                \n",
    "#                 # Step optimizer every gradient_accumulation_steps\n",
    "#                 if (batch_idx + 1) % gradient_accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "#                     # Unscale gradients for proper gradient clipping\n",
    "#                     scaler.unscale_(optimizer)\n",
    "                    \n",
    "#                     # Clip gradients to prevent exploding gradients\n",
    "#                     nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "#                     scaler.step(optimizer)\n",
    "#                     scaler.update()\n",
    "#                     optimizer.zero_grad()\n",
    "#                     if step_count < total_steps:\n",
    "#                         scheduler.step()\n",
    "#                         step_count += 1\n",
    "#             else:\n",
    "#                 # Standard forward pass\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 # Scale loss by gradient accumulation steps\n",
    "#                 loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "#                 # Standard backward pass\n",
    "#                 loss.backward()\n",
    "                \n",
    "#                 # Step optimizer every gradient_accumulation_steps\n",
    "#                 if (batch_idx + 1) % gradient_accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "#                     # Clip gradients to prevent exploding gradients\n",
    "#                     nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "#                     optimizer.step()\n",
    "#                     optimizer.zero_grad()\n",
    "#                     if step_count < total_steps:\n",
    "#                         scheduler.step()\n",
    "#                         step_count += 1\n",
    "            \n",
    "#             # Calculate batch statistics\n",
    "#             batch_loss = loss.item() * gradient_accumulation_steps\n",
    "#             running_loss += batch_loss\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             batch_correct = predicted.eq(labels).sum().item()\n",
    "#             batch_size = labels.size(0)\n",
    "#             total += batch_size\n",
    "#             correct += batch_correct\n",
    "            \n",
    "#             # Measure batch time\n",
    "#             batch_end = time.time()\n",
    "#             batch_time = batch_end - batch_start\n",
    "#             batch_times.append(batch_time)\n",
    "            \n",
    "#             # Update progress bar with detailed metrics\n",
    "#             batch_acc = 100. * batch_correct / batch_size\n",
    "#             current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "#             train_pbar.set_postfix({\n",
    "#                 'loss': f\"{batch_loss:.4f}\",\n",
    "#                 'acc': f\"{batch_acc:.2f}%\",\n",
    "#                 'lr': f\"{current_lr:.6f}\",\n",
    "#                 'time': f\"{batch_time:.3f}s\"\n",
    "#             })\n",
    "#             train_pbar.update()\n",
    "#         torch.save(model.state_dict(), f'/kaggle/working/checkpoints/henet_final_model_epoch_{epoch+1}.pt')\n",
    "        \n",
    "#         train_pbar.close()\n",
    "        \n",
    "#         # Calculate training statistics\n",
    "#         train_loss = running_loss / len(train_loader)\n",
    "#         train_acc = 100. * correct / total\n",
    "#         train_error = 100. - train_acc\n",
    "#         avg_batch_time = sum(batch_times) / len(batch_times) if batch_times else 0\n",
    "        \n",
    "#         # === VALIDATION PHASE ===\n",
    "#         val_metrics = validate_model(model, val_loader, criterion, device, use_amp)\n",
    "#         val_loss = val_metrics['val_loss']\n",
    "        \n",
    "#         # Print epoch summary (now only loss)\n",
    "#         epoch_time = time.time() - epoch_start\n",
    "\n",
    "#         # Print epoch summary\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs} completed in {timedelta(seconds=int(epoch_time))}\")\n",
    "#         print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Train Error: {train_error:.2f}%\")\n",
    "#         print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "#         # Save best model\n",
    "#         if val_loss < best_val_error:\n",
    "#              best_val_error = val_loss\n",
    "#              best_model_state = {\n",
    "#                  'epoch': epoch + 1,\n",
    "#                  'model_state_dict': model.state_dict(),\n",
    "#                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                  'scheduler_state_dict': scheduler.state_dict(),\n",
    "#                  'val_loss': val_loss,\n",
    "#                  'train_error': train_error,\n",
    "#              }\n",
    "#              save_path = os.path.join(save_dir, f\"best_model_epoch{epoch+1}_val{val_loss:.4f}.pt\")\n",
    "        \n",
    "#         # Free up memory\n",
    "#         torch.cuda.empty_cache()\n",
    "    \n",
    "#     # Restore best model if available\n",
    "#     if best_model_state is not None:\n",
    "#         model.load_state_dict(best_model_state['model_state_dict'])\n",
    "#         print(f\"Restored best model with validation error: {best_val_error:.2f}%\")\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# def validate_model(model, val_loader, criterion, device, use_amp=False):\n",
    "#     \"\"\"\n",
    "#     Evaluation-phase (during training): only average loss.\n",
    "#     Returns: {'val_loss': float}\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     total_samples = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "#             # inputs: [B, P, C, H, W] or [B, C, H, W]\n",
    "#             B = labels.size(0)\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#             # flatten patches if needed\n",
    "#             if inputs.ndim == 5:\n",
    "#                 B, P, C, H, W = inputs.shape\n",
    "#                 inputs = inputs.view(B*P, C, H, W)\n",
    "\n",
    "#             # forward\n",
    "#             if use_amp and device != 'cpu':\n",
    "#                 with autocast():\n",
    "#                     outputs = model(inputs)\n",
    "#                     loss = criterion(outputs, labels.repeat_interleave(inputs.size(0)//B))\n",
    "#             else:\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels.repeat_interleave(inputs.size(0)//B))\n",
    "\n",
    "#             total_loss += loss.item() * B\n",
    "#             total_samples += B\n",
    "\n",
    "#     return {'val_loss': total_loss / total_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff4a7c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:27:18.124012Z",
     "iopub.status.busy": "2025-05-20T18:27:18.123740Z",
     "iopub.status.idle": "2025-05-20T18:27:18.127656Z",
     "shell.execute_reply": "2025-05-20T18:27:18.127104Z"
    },
    "papermill": {
     "duration": 0.379039,
     "end_time": "2025-05-20T18:27:18.128796",
     "exception": false,
     "start_time": "2025-05-20T18:27:17.749757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # main.py\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# import os\n",
    "# import gc\n",
    "\n",
    "# # Set device and enable deterministic mode for reproducibility\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# # Print GPU info\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "#     device_cap = torch.cuda.get_device_capability(0)\n",
    "#     print(f\"CUDA Capability: {device_cap[0]}.{device_cap[1]}\")\n",
    "#     print(f\"Total memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f} GB\")\n",
    "\n",
    "# # Clean up memory before starting\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Hyperparameters\n",
    "# num_classes = 2383\n",
    "# batch_size = 64  # Base batch size\n",
    "# num_epochs = 10\n",
    "# beta = 0.5  # HE Block mask weight\n",
    "\n",
    "# # Create the model with optimized HEBlock\n",
    "# model = HENet(num_classes=num_classes, beta=beta)\n",
    "\n",
    "# # Configure DataLoader with optimal settings\n",
    "# train_loader = train_font_loader\n",
    "# val_loader = val_font_loader\n",
    "# test_loader = test_font_loader\n",
    "\n",
    "# # Train the model with optimizations\n",
    "# trained_model = train_model_optimized(\n",
    "#     model, \n",
    "#     train_loader, \n",
    "#     val_loader, \n",
    "#     num_epochs=num_epochs, \n",
    "#     device=device,\n",
    "#     use_amp=True,          # Enable Mixed Precision\n",
    "#     use_compile=False,     # Disable torch.compile for P100\n",
    "#     gradient_accumulation_steps=2,  # Effective batch size = 64 * 4 = 256\n",
    "#     save_dir='/kaggle/working/checkpoints'\n",
    "# )\n",
    "\n",
    "# # Save the final trained model\n",
    "# # torch.save(trained_model.state_dict(), '/kaggle/working/checkpoints/henet_final_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53ee0f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:27:18.951995Z",
     "iopub.status.busy": "2025-05-20T18:27:18.951223Z",
     "iopub.status.idle": "2025-05-20T18:27:18.954939Z",
     "shell.execute_reply": "2025-05-20T18:27:18.954259Z"
    },
    "papermill": {
     "duration": 0.450894,
     "end_time": "2025-05-20T18:27:18.956069",
     "exception": false,
     "start_time": "2025-05-20T18:27:18.505175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top1_error, top5_error = evaluate_model_optimized(\n",
    "#     trained_model, \n",
    "#     test_font_loader, \n",
    "#     device=device,\n",
    "#     use_amp=True\n",
    "# )\n",
    "\n",
    "# print(f\"Final Results:\")\n",
    "# print(f\"Top-1 Error: {top1_error:.2f}%\")\n",
    "# print(f\"Top-5 Error: {top5_error:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Font_Detect_Updated v1.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7107437,
     "sourceId": 11356819,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7359793,
     "isSourceIdPinned": true,
     "sourceId": 11802691,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7462849,
     "sourceId": 11874818,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 348151,
     "modelInstanceId": 327270,
     "sourceId": 399921,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 351469,
     "modelInstanceId": 330631,
     "sourceId": 404488,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1967.499144,
   "end_time": "2025-05-20T18:27:23.066423",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-20T17:54:35.567279",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0466c83409454c95bedf57f284727bf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_059215e1ffbb41c7826e5491106afaaf",
       "max": 704.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51abcd193b2240efb5eef10a6008b821",
       "tabbable": null,
       "tooltip": null,
       "value": 704.0
      }
     },
     "059215e1ffbb41c7826e5491106afaaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c698fc66b754f6daf0f135e0220323c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad27160829c74c27b37234236fbf6a2c",
        "IPY_MODEL_d27617dd38cd4dee9d6fcc7a1940ee28",
        "IPY_MODEL_dcd0ee42d81c451da4d61c627ba91b32"
       ],
       "layout": "IPY_MODEL_105fe09d04d7429e811923488ea36713",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0dced3c465b84a69b8f4c96352c43c33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0ded9611c9474f9ba7555207d08bc254": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0e6b41ee942b440b85238e766ebddf9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0f63e8b46b1944639c2c2b82e49af3c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "10478648eccb4457b33efb05b6bd704c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "105fe09d04d7429e811923488ea36713": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "186a38a869fe423e934c7362730e8ee0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18f54bdbda3544b9bf50dfb4ab5891e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "1a37950a10a94c8babf011a48b1108ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1c401fb775cd477ca8832d680e5705c2",
       "placeholder": "​",
       "style": "IPY_MODEL_c554f49a15684e378cae5040e5e9d647",
       "tabbable": null,
       "tooltip": null,
       "value": " 704/704 [05:54&lt;00:00,  3.23it/s, acc=56.8, loss=1.55]"
      }
     },
     "1a744ffe0b9041d59b8f59fa59ad221c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e4343829cc18469e88a2184d696a90f2",
       "max": 313.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_60150bc9c3114e628a8972b198fd8f43",
       "tabbable": null,
       "tooltip": null,
       "value": 313.0
      }
     },
     "1c1341f354584d97afa1bd5ad7f0b476": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1c401fb775cd477ca8832d680e5705c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23f1ac8bd04f4c74851ec5672b60e731": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2477b553074f42db8e3d70016a35fd7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "284eeb7ddb38400db0845f54486f8d2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2a36ee86876d42158510b264643cf158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6769dbbc777746258b7b334438ad045c",
       "placeholder": "​",
       "style": "IPY_MODEL_f4956b7e80764c34baec40ed2fc35563",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 1/5] Val  : 100%"
      }
     },
     "2ae984d14cd94139ac50de4b176c3e00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_63116e1108ad41d1abca3a839c0e8761",
       "placeholder": "​",
       "style": "IPY_MODEL_0dced3c465b84a69b8f4c96352c43c33",
       "tabbable": null,
       "tooltip": null,
       "value": " 703/704 [05:45&lt;00:00,  2.82it/s, acc=90.8, loss=0.276]"
      }
     },
     "2b01a087303c409b852b7cb803098887": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b5e0d89a33f4a39b59db035df9bc2df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2be8d1ad7df7443bb2a52b6425795a6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b248528edb054b07bd79ca7fe7bddcd5",
       "placeholder": "​",
       "style": "IPY_MODEL_0e6b41ee942b440b85238e766ebddf9f",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 5/5] Train: 100%"
      }
     },
     "2dc2d5f2c8744be088ff9fa06955102b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bafa2508ee974109aadb3a2f3a4b9987",
       "max": 313.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0ded9611c9474f9ba7555207d08bc254",
       "tabbable": null,
       "tooltip": null,
       "value": 313.0
      }
     },
     "2e60a629121045c09494d3d1c379d4ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "2e8be3bf78da4354880ce17629c0698a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2ede76a509c94d15adecf7890f745aab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6af375930b2e4329886909cc2e3c6862",
        "IPY_MODEL_cdcf015553c24c439748ce7a96164308",
        "IPY_MODEL_f43131e73f2940518fb1a842207ab7bb"
       ],
       "layout": "IPY_MODEL_91f324f99f09456db7bf94a16e4bb11c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2f7d6867c4574ec38b99a46becefb260": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "301293bee6f34a9b9cc76dcefa34e598": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_abb6634f2c3d42f99a70940f4b0a9613",
       "max": 704.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3199c4fde8304b69ab268ad7d6948203",
       "tabbable": null,
       "tooltip": null,
       "value": 704.0
      }
     },
     "3199c4fde8304b69ab268ad7d6948203": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "37b5169926b1452ab4a45d4dce1b1919": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3af91153ed924eadb5869fa0d4f4b0cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3dd268fffc6949ed81297815d4b06a3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "418866e74da143ae93f320273f8e8927": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80bbc29472fb4f8d9c6d1a33303b3e11",
       "max": 313.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b8baf7cc54b34eec80ed5ce833d19523",
       "tabbable": null,
       "tooltip": null,
       "value": 313.0
      }
     },
     "43eb97373bbb4d5596066ea8334be72a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4548a5f943a843d895bf1a4d850a16e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "467b493db6ae4abc8d060610784040f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "47a95c33b47e47fa8221e7cf16f1f72f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "4a3b1fa1e3854d1ba1350dd1c2b60684": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_544cb3db08864a298174c89cf94b6874",
       "placeholder": "​",
       "style": "IPY_MODEL_37b5169926b1452ab4a45d4dce1b1919",
       "tabbable": null,
       "tooltip": null,
       "value": " 313/313 [00:35&lt;00:00, 11.67it/s, val_acc=86.6, val_loss=0.403]"
      }
     },
     "4de93ca3077e46399c1ed006b0964a08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8424805bc8c8445ebb2ac18cb606562c",
        "IPY_MODEL_d65df921ed0d45be9390447a6e236696",
        "IPY_MODEL_1a37950a10a94c8babf011a48b1108ff"
       ],
       "layout": "IPY_MODEL_47a95c33b47e47fa8221e7cf16f1f72f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4e915216b8a64625bbf3030b19849691": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "51abcd193b2240efb5eef10a6008b821": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "544cb3db08864a298174c89cf94b6874": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "557ec560b4c7482aabf323105df9388f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c71404ec6aa431ea95435d85b0fd8de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5d6785ba0e654009a56c913557bf0637": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d8375a886c9b4ace9ca68d1cc8b64548",
       "max": 313.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2e8be3bf78da4354880ce17629c0698a",
       "tabbable": null,
       "tooltip": null,
       "value": 313.0
      }
     },
     "5dcaaba0f1f446e49646a2da4f592b94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "60150bc9c3114e628a8972b198fd8f43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "621586fbfd6041dcbe7ac0e61cd5cffc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7aafdcf4ea644201a61781b4ed2fbe64",
       "placeholder": "​",
       "style": "IPY_MODEL_fe0f782abee041dc885c98f286fa648b",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 3/5] Val  :  99%"
      }
     },
     "63116e1108ad41d1abca3a839c0e8761": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "635ca6813b044c45808e21fdef73017c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_853d4cdb6b2643149e9c821cb733f1b5",
        "IPY_MODEL_301293bee6f34a9b9cc76dcefa34e598",
        "IPY_MODEL_6839f0a33d644e9b9b6600b6f7a74ffc"
       ],
       "layout": "IPY_MODEL_abd19c0fbb7946da85199a06b9ac9402",
       "tabbable": null,
       "tooltip": null
      }
     },
     "649f6d3635654b9fb0718aa231b21f4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2a36ee86876d42158510b264643cf158",
        "IPY_MODEL_2dc2d5f2c8744be088ff9fa06955102b",
        "IPY_MODEL_a1415695275b472c8b284345b60855b3"
       ],
       "layout": "IPY_MODEL_5dcaaba0f1f446e49646a2da4f592b94",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6769dbbc777746258b7b334438ad045c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6839f0a33d644e9b9b6600b6f7a74ffc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dff6c69ca2fd4b97a61ef8c6699d477e",
       "placeholder": "​",
       "style": "IPY_MODEL_f41e769b2ae2450c9f7a707f61e5ff59",
       "tabbable": null,
       "tooltip": null,
       "value": " 703/704 [05:50&lt;00:00,  2.83it/s, acc=81.6, loss=0.569]"
      }
     },
     "6ab9199042db49c1928ab2f02fa49f66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_de0e5e99044f4fb495c9b0805c4fcdef",
       "placeholder": "​",
       "style": "IPY_MODEL_10478648eccb4457b33efb05b6bd704c",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 5/5] Val  :  99%"
      }
     },
     "6af375930b2e4329886909cc2e3c6862": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fc0c9b6064e14bde9e60f57e8cedf4df",
       "placeholder": "​",
       "style": "IPY_MODEL_c167fb5373574f8c9c2d2818e8d58e94",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 2/5] Val  : 100%"
      }
     },
     "6e3d3a5acd774497aca188d9eb84fb40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7262fc28edb04f289108cf61e65d295c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78de3ca1c1ea48eba1e4b415088efbcb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a02433076a9488cbaaed6008992a2f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b01a087303c409b852b7cb803098887",
       "max": 704.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_467b493db6ae4abc8d060610784040f2",
       "tabbable": null,
       "tooltip": null,
       "value": 704.0
      }
     },
     "7aafdcf4ea644201a61781b4ed2fbe64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b545aafae4448ad8f62dec084443400": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cfef9e68c3b435f99a5c0b08b57d881": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e83dada0d1340c8bf7057fff4f50a05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e3d3a5acd774497aca188d9eb84fb40",
       "placeholder": "​",
       "style": "IPY_MODEL_f5230d1e6ff649f79d10349ec44ac8db",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 4/5] Train: 100%"
      }
     },
     "80bbc29472fb4f8d9c6d1a33303b3e11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8424805bc8c8445ebb2ac18cb606562c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_557ec560b4c7482aabf323105df9388f",
       "placeholder": "​",
       "style": "IPY_MODEL_284eeb7ddb38400db0845f54486f8d2a",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 1/5] Train: 100%"
      }
     },
     "853d4cdb6b2643149e9c821cb733f1b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bcbb69d7fb084cfb997f0471ae040981",
       "placeholder": "​",
       "style": "IPY_MODEL_2b5e0d89a33f4a39b59db035df9bc2df",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 2/5] Train: 100%"
      }
     },
     "86a3dd36dab34877aee8efb19a458df5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d7a7090d435e456ea2260ff1e047c9a6",
       "placeholder": "​",
       "style": "IPY_MODEL_7b545aafae4448ad8f62dec084443400",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 4/5] Val  : 100%"
      }
     },
     "873a653669ff4f479bbc4d2f04b0b0c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91cd464c09264b7a919e2313eec197af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7262fc28edb04f289108cf61e65d295c",
       "placeholder": "​",
       "style": "IPY_MODEL_0f63e8b46b1944639c2c2b82e49af3c6",
       "tabbable": null,
       "tooltip": null,
       "value": " 310/313 [00:37&lt;00:00,  9.39it/s, val_acc=89.2, val_loss=0.31]"
      }
     },
     "91f324f99f09456db7bf94a16e4bb11c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "9ab068ff45a14b719d04956571e88065": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "a1415695275b472c8b284345b60855b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4548a5f943a843d895bf1a4d850a16e1",
       "placeholder": "​",
       "style": "IPY_MODEL_1c1341f354584d97afa1bd5ad7f0b476",
       "tabbable": null,
       "tooltip": null,
       "value": " 312/313 [00:35&lt;00:00, 10.54it/s, val_acc=75.5, val_loss=0.772]"
      }
     },
     "abb6634f2c3d42f99a70940f4b0a9613": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abd19c0fbb7946da85199a06b9ac9402": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "ad27160829c74c27b37234236fbf6a2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c2efb4dd875c4687af952515b0c22ad9",
       "placeholder": "​",
       "style": "IPY_MODEL_23f1ac8bd04f4c74851ec5672b60e731",
       "tabbable": null,
       "tooltip": null,
       "value": "[Epoch 3/5] Train: 100%"
      }
     },
     "b16400b7d5cb40e586e2bae8c838f554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7e83dada0d1340c8bf7057fff4f50a05",
        "IPY_MODEL_0466c83409454c95bedf57f284727bf3",
        "IPY_MODEL_2ae984d14cd94139ac50de4b176c3e00"
       ],
       "layout": "IPY_MODEL_4e915216b8a64625bbf3030b19849691",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b248528edb054b07bd79ca7fe7bddcd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7ce2b068a3a468d88e1e462721c75fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f38b07b525f749ed9e06af019ff812b0",
       "placeholder": "​",
       "style": "IPY_MODEL_43eb97373bbb4d5596066ea8334be72a",
       "tabbable": null,
       "tooltip": null,
       "value": " 703/704 [05:44&lt;00:00,  2.89it/s, acc=92.5, loss=0.221]"
      }
     },
     "b8baf7cc54b34eec80ed5ce833d19523": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "badbe36a197d4391b2931512ff1e820c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bafa2508ee974109aadb3a2f3a4b9987": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb8982ca64a84928aa317bcb7d695a33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2be8d1ad7df7443bb2a52b6425795a6a",
        "IPY_MODEL_7a02433076a9488cbaaed6008992a2f8",
        "IPY_MODEL_b7ce2b068a3a468d88e1e462721c75fe"
       ],
       "layout": "IPY_MODEL_9ab068ff45a14b719d04956571e88065",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bcbb69d7fb084cfb997f0471ae040981": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c167fb5373574f8c9c2d2818e8d58e94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c2efb4dd875c4687af952515b0c22ad9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c554f49a15684e378cae5040e5e9d647": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c86d08488f2b42c987aacba59e5c649d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6ab9199042db49c1928ab2f02fa49f66",
        "IPY_MODEL_418866e74da143ae93f320273f8e8927",
        "IPY_MODEL_91cd464c09264b7a919e2313eec197af"
       ],
       "layout": "IPY_MODEL_e44a035179a24887825e86aabdbab8d1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cdcf015553c24c439748ce7a96164308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_873a653669ff4f479bbc4d2f04b0b0c1",
       "max": 313.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5c71404ec6aa431ea95435d85b0fd8de",
       "tabbable": null,
       "tooltip": null,
       "value": 313.0
      }
     },
     "d168c70866bf426dafce326672312bff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d27617dd38cd4dee9d6fcc7a1940ee28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2477b553074f42db8e3d70016a35fd7a",
       "max": 704.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2f7d6867c4574ec38b99a46becefb260",
       "tabbable": null,
       "tooltip": null,
       "value": 704.0
      }
     },
     "d4b771ffcbed4ad68f867b0cbe95af39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d65df921ed0d45be9390447a6e236696": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_badbe36a197d4391b2931512ff1e820c",
       "max": 704.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d4b771ffcbed4ad68f867b0cbe95af39",
       "tabbable": null,
       "tooltip": null,
       "value": 704.0
      }
     },
     "d7a7090d435e456ea2260ff1e047c9a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8375a886c9b4ace9ca68d1cc8b64548": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db2a94156159466aa1f365d6c9342f07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_186a38a869fe423e934c7362730e8ee0",
       "placeholder": "​",
       "style": "IPY_MODEL_3dd268fffc6949ed81297815d4b06a3f",
       "tabbable": null,
       "tooltip": null,
       "value": " 311/313 [00:35&lt;00:00, 10.42it/s, val_acc=88.6, val_loss=0.335]"
      }
     },
     "dcd0ee42d81c451da4d61c627ba91b32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78de3ca1c1ea48eba1e4b415088efbcb",
       "placeholder": "​",
       "style": "IPY_MODEL_3af91153ed924eadb5869fa0d4f4b0cb",
       "tabbable": null,
       "tooltip": null,
       "value": " 703/704 [05:48&lt;00:00,  2.77it/s, acc=87.9, loss=0.369]"
      }
     },
     "de0e5e99044f4fb495c9b0805c4fcdef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dff6c69ca2fd4b97a61ef8c6699d477e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4343829cc18469e88a2184d696a90f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e44a035179a24887825e86aabdbab8d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "f1881bbf265c4f7c9832e6775f4876c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_86a3dd36dab34877aee8efb19a458df5",
        "IPY_MODEL_5d6785ba0e654009a56c913557bf0637",
        "IPY_MODEL_4a3b1fa1e3854d1ba1350dd1c2b60684"
       ],
       "layout": "IPY_MODEL_2e60a629121045c09494d3d1c379d4ff",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f38b07b525f749ed9e06af019ff812b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3ad8fc4116e475790de5aea23513d42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_621586fbfd6041dcbe7ac0e61cd5cffc",
        "IPY_MODEL_1a744ffe0b9041d59b8f59fa59ad221c",
        "IPY_MODEL_db2a94156159466aa1f365d6c9342f07"
       ],
       "layout": "IPY_MODEL_18f54bdbda3544b9bf50dfb4ab5891e3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f41e769b2ae2450c9f7a707f61e5ff59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f43131e73f2940518fb1a842207ab7bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7cfef9e68c3b435f99a5c0b08b57d881",
       "placeholder": "​",
       "style": "IPY_MODEL_d168c70866bf426dafce326672312bff",
       "tabbable": null,
       "tooltip": null,
       "value": " 312/313 [00:35&lt;00:00, 10.93it/s, val_acc=84.5, val_loss=0.472]"
      }
     },
     "f4956b7e80764c34baec40ed2fc35563": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f5230d1e6ff649f79d10349ec44ac8db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fc0c9b6064e14bde9e60f57e8cedf4df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe0f782abee041dc885c98f286fa648b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
